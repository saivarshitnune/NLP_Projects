{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDTyiD7w+z+PZ7Nx2G7EUi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ef78e304d5e040f78afc5e06eb16b211": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a62c4ccdcf0d45fab74fdb4446fe6117",
              "IPY_MODEL_735e953de120438fa58b3e2ce369c4cf",
              "IPY_MODEL_24173b1ce68041c5967bfbc05373949e"
            ],
            "layout": "IPY_MODEL_4cc207fa1d55452bbd51b53b091ee325"
          }
        },
        "a62c4ccdcf0d45fab74fdb4446fe6117": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_146bd5a959344451af15956506fe973e",
            "placeholder": "​",
            "style": "IPY_MODEL_1d83b157ac6347cea5b900f84962c6c8",
            "value": "modules.json: 100%"
          }
        },
        "735e953de120438fa58b3e2ce369c4cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9a4cc7d6fa142bd8060484e4c37682c",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65095e4866464285aed5dbced1cea2cf",
            "value": 349
          }
        },
        "24173b1ce68041c5967bfbc05373949e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e71fd10b54794bdfa5e47217675b7c4a",
            "placeholder": "​",
            "style": "IPY_MODEL_46382d08565d478da772792d859ea822",
            "value": " 349/349 [00:00&lt;00:00, 12.0kB/s]"
          }
        },
        "4cc207fa1d55452bbd51b53b091ee325": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "146bd5a959344451af15956506fe973e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d83b157ac6347cea5b900f84962c6c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9a4cc7d6fa142bd8060484e4c37682c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65095e4866464285aed5dbced1cea2cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e71fd10b54794bdfa5e47217675b7c4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46382d08565d478da772792d859ea822": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1a05fb1da7c43bca9f28ff089ed5ecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3371d14c8adf4180869c74d2a7570733",
              "IPY_MODEL_1654355e277f4d88a2bae5b0e2c03031",
              "IPY_MODEL_aacbcc1e262041f78687f5a444959e38"
            ],
            "layout": "IPY_MODEL_48f15ff49380495a9e0f3e59712e6c2c"
          }
        },
        "3371d14c8adf4180869c74d2a7570733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37f0dd4f642e4a63b8e1603c6447f1c7",
            "placeholder": "​",
            "style": "IPY_MODEL_cc43be5d5a78409486fcc7ba1b337203",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "1654355e277f4d88a2bae5b0e2c03031": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_864bc873e8464db08e19f6ee7fe3df40",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc708b563dbf4cb98439a317cb411f2b",
            "value": 116
          }
        },
        "aacbcc1e262041f78687f5a444959e38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8649e3a6aefb4fdda69954b30c02791a",
            "placeholder": "​",
            "style": "IPY_MODEL_68d83a1cbc2f4a6991114594a33a31d5",
            "value": " 116/116 [00:00&lt;00:00, 6.25kB/s]"
          }
        },
        "48f15ff49380495a9e0f3e59712e6c2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37f0dd4f642e4a63b8e1603c6447f1c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc43be5d5a78409486fcc7ba1b337203": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "864bc873e8464db08e19f6ee7fe3df40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc708b563dbf4cb98439a317cb411f2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8649e3a6aefb4fdda69954b30c02791a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68d83a1cbc2f4a6991114594a33a31d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "375b49439c69490abfb2e5b45dfe2b52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0930c219d9ba41de831196c4286be70a",
              "IPY_MODEL_4cb8a0330faa49d5814a3e23ab28f6cb",
              "IPY_MODEL_a878e3e69cbf45ac9ccc940e8c56bcb9"
            ],
            "layout": "IPY_MODEL_46498700ede24aad95b3f8f3064f91a4"
          }
        },
        "0930c219d9ba41de831196c4286be70a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b93bb95e369480cb8c251f18b0f4856",
            "placeholder": "​",
            "style": "IPY_MODEL_fb2713500cbf43d0b1d5f113044f3a4e",
            "value": "README.md: 100%"
          }
        },
        "4cb8a0330faa49d5814a3e23ab28f6cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_faf9aa3c5bb44f55bcd4c22baa19488a",
            "max": 10621,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ebb0b7d6f4c4d54be7d9f5fd57081cc",
            "value": 10621
          }
        },
        "a878e3e69cbf45ac9ccc940e8c56bcb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1bccf32446a4ee190ebdf0fb8b103bf",
            "placeholder": "​",
            "style": "IPY_MODEL_20548a75e0b74ab09b33aeb7ef9d24c5",
            "value": " 10.6k/10.6k [00:00&lt;00:00, 374kB/s]"
          }
        },
        "46498700ede24aad95b3f8f3064f91a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b93bb95e369480cb8c251f18b0f4856": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb2713500cbf43d0b1d5f113044f3a4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "faf9aa3c5bb44f55bcd4c22baa19488a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ebb0b7d6f4c4d54be7d9f5fd57081cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1bccf32446a4ee190ebdf0fb8b103bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20548a75e0b74ab09b33aeb7ef9d24c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0193eb38f5fc4adf8fa9137dc3e0734a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7faf92f2a1f94f5693d52f9bbeb40714",
              "IPY_MODEL_c42c8c99afd446fd93f50738ca0f8019",
              "IPY_MODEL_ec8366c17358408bb6650d41fa774734"
            ],
            "layout": "IPY_MODEL_343a2329af2845efb784879a7dc77201"
          }
        },
        "7faf92f2a1f94f5693d52f9bbeb40714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f36ee6dab3a4f00bff8bcb15633396a",
            "placeholder": "​",
            "style": "IPY_MODEL_a2de2797cb6148fa909dd455c199a511",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "c42c8c99afd446fd93f50738ca0f8019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8be5408a5c224a168cc31687145f0fd3",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_420c9ab6c40240318730974f2f5c90aa",
            "value": 53
          }
        },
        "ec8366c17358408bb6650d41fa774734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a540d10353504a91b77a967c6c6d9f69",
            "placeholder": "​",
            "style": "IPY_MODEL_ca44479223a5412b9bc5bf000c8d7699",
            "value": " 53.0/53.0 [00:00&lt;00:00, 2.48kB/s]"
          }
        },
        "343a2329af2845efb784879a7dc77201": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f36ee6dab3a4f00bff8bcb15633396a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2de2797cb6148fa909dd455c199a511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8be5408a5c224a168cc31687145f0fd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "420c9ab6c40240318730974f2f5c90aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a540d10353504a91b77a967c6c6d9f69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca44479223a5412b9bc5bf000c8d7699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59b51f6275894abc876e64a01693466e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d782ff54e8b14f918437887dc58bcf84",
              "IPY_MODEL_791f2822906f45e0bf43262c0fd94dcf",
              "IPY_MODEL_16b5dd4644a4470da40f58f60b695641"
            ],
            "layout": "IPY_MODEL_ced6e163bc0b43fc99b6d6118e4c8d6e"
          }
        },
        "d782ff54e8b14f918437887dc58bcf84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_deaefd2249eb4198a7368eefb63c4d81",
            "placeholder": "​",
            "style": "IPY_MODEL_051884c29b004930b639661bf88c691b",
            "value": "config.json: 100%"
          }
        },
        "791f2822906f45e0bf43262c0fd94dcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d845396d27f4782bbc2e8c7ea19e694",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17d2ced61ff541d685d65559096e089f",
            "value": 571
          }
        },
        "16b5dd4644a4470da40f58f60b695641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ad852f112754ae7928e55925e5707f3",
            "placeholder": "​",
            "style": "IPY_MODEL_37503f7bc52e4c42a468f8d0d6a27be5",
            "value": " 571/571 [00:00&lt;00:00, 19.8kB/s]"
          }
        },
        "ced6e163bc0b43fc99b6d6118e4c8d6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "deaefd2249eb4198a7368eefb63c4d81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "051884c29b004930b639661bf88c691b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d845396d27f4782bbc2e8c7ea19e694": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17d2ced61ff541d685d65559096e089f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ad852f112754ae7928e55925e5707f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37503f7bc52e4c42a468f8d0d6a27be5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d87206bb87164d8c9244876273e83c76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3bfca893d7d0481c8d7752f88567bd7f",
              "IPY_MODEL_76d396b3ccdb46ffb4ce08b5e3800632",
              "IPY_MODEL_97061cd0b94943bcb6405ca63cff7eb8"
            ],
            "layout": "IPY_MODEL_c87d991a46794f19ae4215cc1cf51828"
          }
        },
        "3bfca893d7d0481c8d7752f88567bd7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffbac36e93634e4ba8d6bb4004d9fa07",
            "placeholder": "​",
            "style": "IPY_MODEL_47b41954983a41bd97168ed2c08f83af",
            "value": "model.safetensors: 100%"
          }
        },
        "76d396b3ccdb46ffb4ce08b5e3800632": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d532626de7c24684bfd4ac8b0dfba1c7",
            "max": 437971872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e58bbdb9ba8f450c8393633dad4ad0f1",
            "value": 437971872
          }
        },
        "97061cd0b94943bcb6405ca63cff7eb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80cea0ce594940bea542d4664c23e5f2",
            "placeholder": "​",
            "style": "IPY_MODEL_a6819cdad62b4d4cbb252ffd9531a381",
            "value": " 438M/438M [00:03&lt;00:00, 165MB/s]"
          }
        },
        "c87d991a46794f19ae4215cc1cf51828": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffbac36e93634e4ba8d6bb4004d9fa07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47b41954983a41bd97168ed2c08f83af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d532626de7c24684bfd4ac8b0dfba1c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e58bbdb9ba8f450c8393633dad4ad0f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "80cea0ce594940bea542d4664c23e5f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6819cdad62b4d4cbb252ffd9531a381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37bd1c586ac148ca84709f4dc7de89e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d51367acb664f0ba524a1b42740ce10",
              "IPY_MODEL_6a3b838e40454a7fb373d98051c95d69",
              "IPY_MODEL_01efb41b554e4dff9f575ae0d8d80521"
            ],
            "layout": "IPY_MODEL_21abdd38b1274cdfac577f73c2b86865"
          }
        },
        "1d51367acb664f0ba524a1b42740ce10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb5796593e794417a8710d50b11c70af",
            "placeholder": "​",
            "style": "IPY_MODEL_3372a50442564c049a4cd890d40056f1",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "6a3b838e40454a7fb373d98051c95d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cd1d842ef0a4d40856dea68a8d4b2c0",
            "max": 363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7688a62cb36e41c7829f9fcf8a277fbd",
            "value": 363
          }
        },
        "01efb41b554e4dff9f575ae0d8d80521": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_863ba846cf4d44f5b91a4d64454734e6",
            "placeholder": "​",
            "style": "IPY_MODEL_574231b2610a47678a88f33f4955269b",
            "value": " 363/363 [00:00&lt;00:00, 17.3kB/s]"
          }
        },
        "21abdd38b1274cdfac577f73c2b86865": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb5796593e794417a8710d50b11c70af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3372a50442564c049a4cd890d40056f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cd1d842ef0a4d40856dea68a8d4b2c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7688a62cb36e41c7829f9fcf8a277fbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "863ba846cf4d44f5b91a4d64454734e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "574231b2610a47678a88f33f4955269b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ae667d9e56a485f96504fd4f5c382f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6299695a058a44db963d00e07e71925d",
              "IPY_MODEL_fa84e8997e8c44e988847bb6a6521b60",
              "IPY_MODEL_c4e088539ec345518664b05f2d103b01"
            ],
            "layout": "IPY_MODEL_45df0e2c8e6f4e87b4c86f35ea99b2d4"
          }
        },
        "6299695a058a44db963d00e07e71925d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7449f3bd310d4aeea61bef39df6d6a88",
            "placeholder": "​",
            "style": "IPY_MODEL_57d50936ab634a89bfcf62e4a0eafa79",
            "value": "vocab.txt: 100%"
          }
        },
        "fa84e8997e8c44e988847bb6a6521b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9b205e909344fdfb80047aedf5572d7",
            "max": 231536,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65be02b405f241e6b2be9f7c729d7263",
            "value": 231536
          }
        },
        "c4e088539ec345518664b05f2d103b01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab03148fb0a14624ac9fa09ba5a9e434",
            "placeholder": "​",
            "style": "IPY_MODEL_be14f5c3f76a4797987078376258043f",
            "value": " 232k/232k [00:00&lt;00:00, 5.22MB/s]"
          }
        },
        "45df0e2c8e6f4e87b4c86f35ea99b2d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7449f3bd310d4aeea61bef39df6d6a88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57d50936ab634a89bfcf62e4a0eafa79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9b205e909344fdfb80047aedf5572d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65be02b405f241e6b2be9f7c729d7263": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab03148fb0a14624ac9fa09ba5a9e434": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be14f5c3f76a4797987078376258043f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8301c46c90db4c17be4988ba0a53a361": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5a283f4319f4c039b26c34a6a53b0a7",
              "IPY_MODEL_8f14be035a9d46928d268948adf77eb2",
              "IPY_MODEL_f4f3b4c944974e3fb008d7b67b24a088"
            ],
            "layout": "IPY_MODEL_c7e1df5e08f641fba502b94c1ebd5a54"
          }
        },
        "c5a283f4319f4c039b26c34a6a53b0a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eac5f52b0cb84b3485093ce6c0571e55",
            "placeholder": "​",
            "style": "IPY_MODEL_ae7267a2cfbe430098dc790a8da3ee89",
            "value": "tokenizer.json: 100%"
          }
        },
        "8f14be035a9d46928d268948adf77eb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3f1d972c04b4ecd817e8913acd9b738",
            "max": 466021,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_024d7bebb24048a296b43dbdf3c4a618",
            "value": 466021
          }
        },
        "f4f3b4c944974e3fb008d7b67b24a088": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c232a74271c0451bb76171e63bda62b3",
            "placeholder": "​",
            "style": "IPY_MODEL_26ff93e712504457aa0f810162750356",
            "value": " 466k/466k [00:00&lt;00:00, 3.53MB/s]"
          }
        },
        "c7e1df5e08f641fba502b94c1ebd5a54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eac5f52b0cb84b3485093ce6c0571e55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae7267a2cfbe430098dc790a8da3ee89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3f1d972c04b4ecd817e8913acd9b738": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "024d7bebb24048a296b43dbdf3c4a618": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c232a74271c0451bb76171e63bda62b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26ff93e712504457aa0f810162750356": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b827d556168c485eb7d82ad30344bed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dcc423f8f22040d0af320de905022a70",
              "IPY_MODEL_7d437632801e43c5b5dc588cd2de0c6c",
              "IPY_MODEL_194f577f8cb742bc9447bafe3af7eafc"
            ],
            "layout": "IPY_MODEL_0fe947e369114ab7a64fe678c2aec6cc"
          }
        },
        "dcc423f8f22040d0af320de905022a70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_681670eebd2646b3a191c4d74190d85c",
            "placeholder": "​",
            "style": "IPY_MODEL_71b6a3f1a58f4021bc6aed7231290254",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "7d437632801e43c5b5dc588cd2de0c6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b980ce01cc4a4eab8410f71a5e18d403",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf07274bb19c44adb7bf058cf91e377e",
            "value": 239
          }
        },
        "194f577f8cb742bc9447bafe3af7eafc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4657ef0bbc36441aaebb3a3be1739b09",
            "placeholder": "​",
            "style": "IPY_MODEL_6101633a0cc24602aea0c7fbeba92657",
            "value": " 239/239 [00:00&lt;00:00, 9.08kB/s]"
          }
        },
        "0fe947e369114ab7a64fe678c2aec6cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "681670eebd2646b3a191c4d74190d85c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71b6a3f1a58f4021bc6aed7231290254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b980ce01cc4a4eab8410f71a5e18d403": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf07274bb19c44adb7bf058cf91e377e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4657ef0bbc36441aaebb3a3be1739b09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6101633a0cc24602aea0c7fbeba92657": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0588239bf7ff46f7a523dea214ebd64d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d6d440eff7741329391ea0ff5ab9fee",
              "IPY_MODEL_b3a777b1343444ac86ecd311d3e3dfba",
              "IPY_MODEL_74bf6dc7be724176ae5639ec2d2d554a"
            ],
            "layout": "IPY_MODEL_dd0d95ddec724904805a5af4f0157a90"
          }
        },
        "9d6d440eff7741329391ea0ff5ab9fee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8c4be3cc8074c318bb49d83569e3592",
            "placeholder": "​",
            "style": "IPY_MODEL_eafdf47c75aa4cdfbd85c99e30429a52",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "b3a777b1343444ac86ecd311d3e3dfba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa002cdc9f884323bb6ddc74d4fc0fc6",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b5195de9b504e9f864e11d16aec27b8",
            "value": 190
          }
        },
        "74bf6dc7be724176ae5639ec2d2d554a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5554387f4cb4d7aa247df91f635f6a9",
            "placeholder": "​",
            "style": "IPY_MODEL_82283a96635e40b38da39344aa498e1c",
            "value": " 190/190 [00:00&lt;00:00, 6.82kB/s]"
          }
        },
        "dd0d95ddec724904805a5af4f0157a90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8c4be3cc8074c318bb49d83569e3592": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eafdf47c75aa4cdfbd85c99e30429a52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa002cdc9f884323bb6ddc74d4fc0fc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b5195de9b504e9f864e11d16aec27b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d5554387f4cb4d7aa247df91f635f6a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82283a96635e40b38da39344aa498e1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saivarshitnune/rag_projects/blob/Varshith/RAG_APP_Mistral_Langchain_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViA5H7wQyFlX",
        "outputId": "29bbb3d2-dfec-4767-f250-c3be83c72850"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTYpSeRwsm3j",
        "outputId": "b26be13b-1274-4eba-8b3f-071c6508e7c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting weaviate-client\n",
            "  Downloading weaviate_client-4.8.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting rapidocr-onnxruntime\n",
            "  Downloading rapidocr_onnxruntime-1.3.24-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.30.0 in /usr/local/lib/python3.10/dist-packages (from weaviate-client) (2.32.3)\n",
            "Collecting httpx<=0.27.0,>=0.25.0 (from weaviate-client)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting validators==0.34.0 (from weaviate-client)\n",
            "  Downloading validators-0.34.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting authlib<1.3.2,>=1.2.1 (from weaviate-client)\n",
            "  Downloading Authlib-1.3.1-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from weaviate-client) (2.9.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.57.0 in /usr/local/lib/python3.10/dist-packages (from weaviate-client) (1.64.1)\n",
            "Collecting grpcio-tools<2.0.0,>=1.57.0 (from weaviate-client)\n",
            "  Downloading grpcio_tools-1.66.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting grpcio-health-checking<2.0.0,>=1.57.0 (from weaviate-client)\n",
            "  Downloading grpcio_health_checking-1.66.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.34)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.4.0,>=0.3.0 (from langchain)\n",
            "  Downloading langchain_core-0.3.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.120-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Collecting pyclipper>=1.2.0 (from rapidocr-onnxruntime)\n",
            "  Downloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: opencv-python>=4.5.1.48 in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (4.10.0.84)\n",
            "Requirement already satisfied: six>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (1.16.0)\n",
            "Requirement already satisfied: Shapely!=2.0.4,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (2.0.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rapidocr-onnxruntime) (9.4.0)\n",
            "Collecting onnxruntime>=1.7.0 (from rapidocr-onnxruntime)\n",
            "  Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.10/dist-packages (from authlib<1.3.2,>=1.2.1->weaviate-client) (43.0.1)\n",
            "Collecting protobuf<6.0dev,>=5.26.1 (from grpcio-health-checking<2.0.0,>=1.57.0->weaviate-client)\n",
            "  Downloading protobuf-5.28.1-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting grpcio<2.0.0,>=1.57.0 (from weaviate-client)\n",
            "  Downloading grpcio-1.66.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools<2.0.0,>=1.57.0->weaviate-client) (71.0.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<=0.27.0,>=0.25.0->weaviate-client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<=0.27.0,>=0.25.0->weaviate-client) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<=0.27.0,>=0.25.0->weaviate-client)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<=0.27.0,>=0.25.0->weaviate-client) (3.8)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<=0.27.0,>=0.25.0->weaviate-client) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<=0.27.0,>=0.25.0->weaviate-client)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.0->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (24.1)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime>=1.7.0->rapidocr-onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (24.3.25)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (1.13.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.0->weaviate-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.0->weaviate-client) (2.23.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.30.0->weaviate-client) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.30.0->weaviate-client) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<=0.27.0,>=0.25.0->weaviate-client) (1.2.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.7.0->rapidocr-onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography->authlib<1.3.2,>=1.2.1->weaviate-client) (1.17.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.7.0->rapidocr-onnxruntime) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography->authlib<1.3.2,>=1.2.1->weaviate-client) (2.22)\n",
            "Downloading weaviate_client-4.8.1-py3-none-any.whl (374 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.5/374.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading validators-0.34.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidocr_onnxruntime-1.3.24-py3-none-any.whl (14.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Authlib-1.3.1-py2.py3-none-any.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.8/223.8 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio_health_checking-1.66.1-py3-none-any.whl (18 kB)\n",
            "Downloading grpcio-1.66.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio_tools-1.66.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.0-py3-none-any.whl (405 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m405.1/405.1 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.120-py3-none-any.whl (289 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.8/289.8 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (908 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-5.28.1-cp38-abi3-manylinux2014_x86_64.whl (316 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: pyclipper, validators, tenacity, pypdf, protobuf, orjson, jsonpointer, humanfriendly, h11, grpcio, tiktoken, jsonpatch, httpcore, grpcio-tools, grpcio-health-checking, coloredlogs, onnxruntime, httpx, authlib, weaviate-client, rapidocr-onnxruntime, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.64.1\n",
            "    Uninstalling grpcio-1.64.1:\n",
            "      Successfully uninstalled grpcio-1.64.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires protobuf<5,>=3.20, but you have protobuf 5.28.1 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.6 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.1 which is incompatible.\n",
            "google-cloud-datastore 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.1 which is incompatible.\n",
            "google-cloud-firestore 2.16.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.1 which is incompatible.\n",
            "tensorboard 2.17.0 requires protobuf!=4.24.0,<5.0.0,>=3.19.6, but you have protobuf 5.28.1 which is incompatible.\n",
            "tensorflow 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.28.1 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 5.28.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed authlib-1.3.1 coloredlogs-15.0.1 grpcio-1.66.1 grpcio-health-checking-1.66.1 grpcio-tools-1.66.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 humanfriendly-10.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.0 langchain-core-0.3.0 langchain-text-splitters-0.3.0 langsmith-0.1.120 onnxruntime-1.19.2 orjson-3.10.7 protobuf-5.28.1 pyclipper-1.3.0.post5 pypdf-4.3.1 rapidocr-onnxruntime-1.3.24 tenacity-8.5.0 tiktoken-0.7.0 validators-0.34.0 weaviate-client-4.8.1\n"
          ]
        }
      ],
      "source": [
        "!pip install weaviate-client langchain tiktoken pypdf rapidocr-onnxruntime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WEAVIATE_CLUSTER=\"https://sterw1rbrgwbwp7lkaqfxg.c0.us-west3.gcp.weaviate.cloud\"\n",
        "WEAVIATE_API_KEY='GEU6OecVCMuS5zxaCngWUG9u4hPE7YeRSvd6'"
      ],
      "metadata": {
        "id": "MIfTk8jks5No"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72t4DDZ3vJ_M",
        "outputId": "053b7a20-dc4b-4bcc-8ce8-1e32794d4714"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.34)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.10.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.0)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.120)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.0->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.0->langchain-community) (2.9.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain-community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-community) (0.27.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-community) (3.10.7)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.0->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.0->langchain-community) (2.23.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (1.2.2)\n",
            "Downloading langchain_community-0.3.0-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n",
            "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain-community-0.3.0 marshmallow-3.22.0 mypy-extensions-1.0.0 pydantic-settings-2.5.2 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Weaviate\n",
        "import weaviate\n",
        "\n",
        "WEAVIATE_URL = WEAVIATE_CLUSTER\n",
        "WEAVIATE_API_KEY = WEAVIATE_API_KEY\n",
        "\n",
        "client = weaviate.Client(\n",
        "    url=WEAVIATE_URL, auth_client_secret=weaviate.AuthApiKey(WEAVIATE_API_KEY))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "380ZOM6Yt-V7",
        "outputId": "d88f3c01-63b7-4f9e-e788-6cdecab46ad4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-28ed2dfcd71e>:7: DeprecationWarning: \n",
            "Python client v3 `weaviate.Client(...)` connections and methods are deprecated and will\n",
            "            be removed by 2024-11-30.\n",
            "\n",
            "            Upgrade your code to use Python client v4 `weaviate.WeaviateClient` connections and methods.\n",
            "                - For Python Client v4 usage, see: https://weaviate.io/developers/weaviate/client-libraries/python\n",
            "                - For code migration, see: https://weaviate.io/developers/weaviate/client-libraries/python/v3_v4_migration\n",
            "\n",
            "            If you have to use v3 code, install the v3 client and pin the v3 dependency in your requirements file: `weaviate-client>=3.26.7;<4.0.0`\n",
            "  client = weaviate.Client(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #fixing unicode error in google colab\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "c_pePYeguZEd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZPWzRfKvsCu",
        "outputId": "b333e5a9-636c-4935-e4f2-781be737c8f1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-3.1.0-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.44.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.4.0+cu121)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.24.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence-transformers) (3.16.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence-transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->sentence-transformers) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Downloading sentence_transformers-3.1.0-py3-none-any.whl (249 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.1/249.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentence-transformers\n",
            "Successfully installed sentence-transformers-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# specify embedding model (using huggingface sentence transformer)\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "embedding_model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "#model_kwargs = {\"device\": \"cuda\"}\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "  model_name=embedding_model_name,\n",
        "  #model_kwargs=model_kwargs\n",
        ")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681,
          "referenced_widgets": [
            "ef78e304d5e040f78afc5e06eb16b211",
            "a62c4ccdcf0d45fab74fdb4446fe6117",
            "735e953de120438fa58b3e2ce369c4cf",
            "24173b1ce68041c5967bfbc05373949e",
            "4cc207fa1d55452bbd51b53b091ee325",
            "146bd5a959344451af15956506fe973e",
            "1d83b157ac6347cea5b900f84962c6c8",
            "d9a4cc7d6fa142bd8060484e4c37682c",
            "65095e4866464285aed5dbced1cea2cf",
            "e71fd10b54794bdfa5e47217675b7c4a",
            "46382d08565d478da772792d859ea822",
            "c1a05fb1da7c43bca9f28ff089ed5ecb",
            "3371d14c8adf4180869c74d2a7570733",
            "1654355e277f4d88a2bae5b0e2c03031",
            "aacbcc1e262041f78687f5a444959e38",
            "48f15ff49380495a9e0f3e59712e6c2c",
            "37f0dd4f642e4a63b8e1603c6447f1c7",
            "cc43be5d5a78409486fcc7ba1b337203",
            "864bc873e8464db08e19f6ee7fe3df40",
            "cc708b563dbf4cb98439a317cb411f2b",
            "8649e3a6aefb4fdda69954b30c02791a",
            "68d83a1cbc2f4a6991114594a33a31d5",
            "375b49439c69490abfb2e5b45dfe2b52",
            "0930c219d9ba41de831196c4286be70a",
            "4cb8a0330faa49d5814a3e23ab28f6cb",
            "a878e3e69cbf45ac9ccc940e8c56bcb9",
            "46498700ede24aad95b3f8f3064f91a4",
            "6b93bb95e369480cb8c251f18b0f4856",
            "fb2713500cbf43d0b1d5f113044f3a4e",
            "faf9aa3c5bb44f55bcd4c22baa19488a",
            "1ebb0b7d6f4c4d54be7d9f5fd57081cc",
            "c1bccf32446a4ee190ebdf0fb8b103bf",
            "20548a75e0b74ab09b33aeb7ef9d24c5",
            "0193eb38f5fc4adf8fa9137dc3e0734a",
            "7faf92f2a1f94f5693d52f9bbeb40714",
            "c42c8c99afd446fd93f50738ca0f8019",
            "ec8366c17358408bb6650d41fa774734",
            "343a2329af2845efb784879a7dc77201",
            "6f36ee6dab3a4f00bff8bcb15633396a",
            "a2de2797cb6148fa909dd455c199a511",
            "8be5408a5c224a168cc31687145f0fd3",
            "420c9ab6c40240318730974f2f5c90aa",
            "a540d10353504a91b77a967c6c6d9f69",
            "ca44479223a5412b9bc5bf000c8d7699",
            "59b51f6275894abc876e64a01693466e",
            "d782ff54e8b14f918437887dc58bcf84",
            "791f2822906f45e0bf43262c0fd94dcf",
            "16b5dd4644a4470da40f58f60b695641",
            "ced6e163bc0b43fc99b6d6118e4c8d6e",
            "deaefd2249eb4198a7368eefb63c4d81",
            "051884c29b004930b639661bf88c691b",
            "8d845396d27f4782bbc2e8c7ea19e694",
            "17d2ced61ff541d685d65559096e089f",
            "5ad852f112754ae7928e55925e5707f3",
            "37503f7bc52e4c42a468f8d0d6a27be5",
            "d87206bb87164d8c9244876273e83c76",
            "3bfca893d7d0481c8d7752f88567bd7f",
            "76d396b3ccdb46ffb4ce08b5e3800632",
            "97061cd0b94943bcb6405ca63cff7eb8",
            "c87d991a46794f19ae4215cc1cf51828",
            "ffbac36e93634e4ba8d6bb4004d9fa07",
            "47b41954983a41bd97168ed2c08f83af",
            "d532626de7c24684bfd4ac8b0dfba1c7",
            "e58bbdb9ba8f450c8393633dad4ad0f1",
            "80cea0ce594940bea542d4664c23e5f2",
            "a6819cdad62b4d4cbb252ffd9531a381",
            "37bd1c586ac148ca84709f4dc7de89e6",
            "1d51367acb664f0ba524a1b42740ce10",
            "6a3b838e40454a7fb373d98051c95d69",
            "01efb41b554e4dff9f575ae0d8d80521",
            "21abdd38b1274cdfac577f73c2b86865",
            "fb5796593e794417a8710d50b11c70af",
            "3372a50442564c049a4cd890d40056f1",
            "2cd1d842ef0a4d40856dea68a8d4b2c0",
            "7688a62cb36e41c7829f9fcf8a277fbd",
            "863ba846cf4d44f5b91a4d64454734e6",
            "574231b2610a47678a88f33f4955269b",
            "1ae667d9e56a485f96504fd4f5c382f3",
            "6299695a058a44db963d00e07e71925d",
            "fa84e8997e8c44e988847bb6a6521b60",
            "c4e088539ec345518664b05f2d103b01",
            "45df0e2c8e6f4e87b4c86f35ea99b2d4",
            "7449f3bd310d4aeea61bef39df6d6a88",
            "57d50936ab634a89bfcf62e4a0eafa79",
            "c9b205e909344fdfb80047aedf5572d7",
            "65be02b405f241e6b2be9f7c729d7263",
            "ab03148fb0a14624ac9fa09ba5a9e434",
            "be14f5c3f76a4797987078376258043f",
            "8301c46c90db4c17be4988ba0a53a361",
            "c5a283f4319f4c039b26c34a6a53b0a7",
            "8f14be035a9d46928d268948adf77eb2",
            "f4f3b4c944974e3fb008d7b67b24a088",
            "c7e1df5e08f641fba502b94c1ebd5a54",
            "eac5f52b0cb84b3485093ce6c0571e55",
            "ae7267a2cfbe430098dc790a8da3ee89",
            "f3f1d972c04b4ecd817e8913acd9b738",
            "024d7bebb24048a296b43dbdf3c4a618",
            "c232a74271c0451bb76171e63bda62b3",
            "26ff93e712504457aa0f810162750356",
            "b827d556168c485eb7d82ad30344bed1",
            "dcc423f8f22040d0af320de905022a70",
            "7d437632801e43c5b5dc588cd2de0c6c",
            "194f577f8cb742bc9447bafe3af7eafc",
            "0fe947e369114ab7a64fe678c2aec6cc",
            "681670eebd2646b3a191c4d74190d85c",
            "71b6a3f1a58f4021bc6aed7231290254",
            "b980ce01cc4a4eab8410f71a5e18d403",
            "bf07274bb19c44adb7bf058cf91e377e",
            "4657ef0bbc36441aaebb3a3be1739b09",
            "6101633a0cc24602aea0c7fbeba92657",
            "0588239bf7ff46f7a523dea214ebd64d",
            "9d6d440eff7741329391ea0ff5ab9fee",
            "b3a777b1343444ac86ecd311d3e3dfba",
            "74bf6dc7be724176ae5639ec2d2d554a",
            "dd0d95ddec724904805a5af4f0157a90",
            "d8c4be3cc8074c318bb49d83569e3592",
            "eafdf47c75aa4cdfbd85c99e30429a52",
            "fa002cdc9f884323bb6ddc74d4fc0fc6",
            "0b5195de9b504e9f864e11d16aec27b8",
            "d5554387f4cb4d7aa247df91f635f6a9",
            "82283a96635e40b38da39344aa498e1c"
          ]
        },
        "id": "ff7bwCQbvr-E",
        "outputId": "d6af699f-e035-44da-af1a-0cdd599886cd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPIEmbeddings has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "<ipython-input-9-a64f1f9a5557>:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
            "  embeddings = HuggingFaceEmbeddings(\n",
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef78e304d5e040f78afc5e06eb16b211"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1a05fb1da7c43bca9f28ff089ed5ecb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "375b49439c69490abfb2e5b45dfe2b52"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0193eb38f5fc4adf8fa9137dc3e0734a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59b51f6275894abc876e64a01693466e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d87206bb87164d8c9244876273e83c76"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37bd1c586ac148ca84709f4dc7de89e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ae667d9e56a485f96504fd4f5c382f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8301c46c90db4c17be4988ba0a53a361"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b827d556168c485eb7d82ad30344bed1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0588239bf7ff46f7a523dea214ebd64d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "loader = PyPDFLoader(\"/content/drive/MyDrive/Ragas.pdf\", extract_images=True)\n",
        "pages = loader.load()"
      ],
      "metadata": {
        "id": "CA23XnZ3v7Z5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASGNMaQ1zSLg",
        "outputId": "c8fccd56-aacc-4e85-a884-c9e9f031e4a2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 0}, page_content='RAGAS: Automated Evaluation of Retrieval Augmented Generation\\nShahul Es†, Jithin James†, Luis Espinosa-Anke∗♢, Steven Schockaert∗\\n†Exploding Gradients\\n∗CardiffNLP, Cardiff University, United Kingdom\\n♢AMPLYFI, United Kingdom\\nshahules786@gmail.com,jamesjithin97@gmail.com\\n{espinosa-ankel,schockaerts1}@cardiff.ac.uk\\nAbstract\\nWe introduce RAGA S(Retrieval Augmented\\nGeneration Assessment), a framework for\\nreference-free evaluation of Retrieval Aug-\\nmented Generation (RAG) pipelines. RAG\\nsystems are composed of a retrieval and an\\nLLM based generation module, and provide\\nLLMs with knowledge from a reference textual\\ndatabase, which enables them to act as a natu-\\nral language layer between a user and textual\\ndatabases, reducing the risk of hallucinations.\\nEvaluating RAG architectures is, however, chal-\\nlenging because there are several dimensions to\\nconsider: the ability of the retrieval system to\\nidentify relevant and focused context passages,\\nthe ability of the LLM to exploit such passages\\nin a faithful way, or the quality of the gener-\\nation itself. With RAGA S, we put forward a\\nsuite of metrics which can be used to evaluate\\nthese different dimensions without having to\\nrely on ground truth human annotations . We\\nposit that such a framework can crucially con-\\ntribute to faster evaluation cycles of RAG archi-\\ntectures, which is especially important given\\nthe fast adoption of LLMs.\\n1 Introduction\\nLanguage Models (LMs) capture a vast amount\\nof knowledge about the world, which allows them\\nto answer questions without accessing any exter-\\nnal sources. This idea of LMs as repositories of\\nknowledge emerged shortly after the introduction\\nof BERT (Devlin et al., 2019) and became more\\nfirmly established with the introduction of ever\\nlarger LMs (Roberts et al., 2020). While the most\\nrecent Large Language Models (LLMs) capture\\nenough knowledge to rival human performance\\nacross a wide variety of question answering bench-\\nmarks (Bubeck et al., 2023), the idea of using\\nLLMs as knowledge bases still has two fundamen-\\ntal limitations. First, LLMs are not able to answer\\nquestions about events that have happened after\\nthey were trained. Second, even the largest modelsstruggle to memorise knowledge that is only rarely\\nmentioned in the training corpus (Kandpal et al.,\\n2022; Mallen et al., 2023). The standard solution\\nto these issues is to rely on Retrieval Augmented\\nGeneration (RAG) (Lee et al., 2019; Lewis et al.,\\n2020; Guu et al., 2020). Answering a question\\nthen essentially involves retrieving relevant pas-\\nsages from a corpus and feeding these passages,\\nalong with the original question, to the LM. While\\ninitial approaches relied on specialised LMs for\\nretrieval-augmented language modelling (Khandel-\\nwal et al., 2020; Borgeaud et al., 2022), recent work\\nhas suggested that simply adding retrieved docu-\\nments to the input of a standard LM can also work\\nwell (Khattab et al., 2022; Ram et al., 2023; Shi\\net al., 2023), thus making it possible to use retrieval-\\naugmented strategies in combination with LLMs\\nthat are only available through APIs.\\nWhile the usefulness of retrieval-augmented\\nstrategies is clear, their implementation requires\\na significant amount of tuning, as the overall per-\\nformance will be affected by the retrieval model,\\nthe considered corpus, the LM, or the prompt for-\\nmulation, among others. Automated evaluation of\\nretrieval-augmented systems is thus paramount. In\\npractice, RAG systems are often evaluated in terms\\nof the language modelling task itself, i.e. by mea-\\nsuring perplexity on some reference corpus. How-\\never, such evaluations are not always predictive\\nof downstream performance (Wang et al., 2023c).\\nMoreover, this evaluation strategy relies on the LM\\nprobabilities, which are not accessible for some\\nclosed models (e.g. ChatGPT and GPT-4). Ques-\\ntion answering is another common evaluation task,\\nbut usually only datasets with short extractive an-\\nswers are considered, which may not be represen-\\ntative of how the system will be used.\\nTo address these issues, in this paper we present\\nRAGA S1, a framework for the automated assess-\\n1RAGA Sis available at https://github.com/\\nexplodinggradients/ragas .arXiv:2309.15217v1  [cs.CL]  26 Sep 2023'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 1}, page_content='ment of retrieval augmented generation systems.\\nWe focus on settings where reference answers may\\nnot be available, and where we want to estimate\\ndifferent proxies for correctness, in addition to the\\nusefulness of the retrieved passages. The RAGA S\\nframework provides an integration with both llama-\\nindex and Langchain, the most widely used frame-\\nworks for building RAG solutions, thus enabling\\ndevelopers to easily integrate RAGA Sinto their\\nstandard workflow.\\n2 Related Work\\nEstimating faithfulness using LLMs The prob-\\nlem of detecting hallucinations in LLM generated\\nresponses has been extensively studied (Ji et al.,\\n2023). Several authors have suggested the idea\\nof predicting factuality using a few-shot prompt-\\ning strategy (Zhang et al., 2023). Recent analy-\\nses, however, suggest that existing models struggle\\nwith detecting hallucination when using standard\\nprompting strategies (Li et al., 2023; Azaria and\\nMitchell, 2023). Other approaches rely on linking\\nthe generated responses to facts from an external\\nknowledge base (Min et al., 2023), but this is not\\nalways possible.\\nYet another strategy is to inspect the probabili-\\nties assigned to individual tokens, where we would\\nexpect the model to be less confident in halluci-\\nnated answers than in factual ones. For instance,\\nBARTScore (Yuan et al., 2021) estimates factuality\\nby looking at the conditional probability of the gen-\\nerated text given the input. Kadavath et al. (2022)\\nuse a variation of this idea. Starting from the ob-\\nservation that LLMs provide well-calibrated proba-\\nbilities when answering multiple-choice questions,\\nthey essentially convert the problem of validating\\nmodel generated answers into a multiple-choice\\nquestion which asks whether the answer is true or\\nfalse. Rather than looking at the output probabil-\\nities, Azaria and Mitchell (2023) propose to train\\na supervised classifier on the weights from one of\\nthe hidden layers of the LLM, to predict whether a\\ngiven statement is true or not. While the approach\\nperforms well, the need to access the hidden states\\nof the model makes it unsuitable for systems that\\naccess LLMs through an API.\\nFor models that do not provide access to token\\nprobabilities, such as ChatGPT and GPT-4, differ-\\nent methods are needed. SelfCheckGPT (Manakul\\net al., 2023) addresses this problem by instead sam-\\npling multiple answers. Their core idea is thatfactual answers are more stable: when an answer is\\nfactual, we can expect that different samples will\\ntend to be semantically similar, whereas this is less\\nlikely to be the case for hallucinated answers.\\nAutomated evaluation of text generation systems\\nLLMs have also been leveraged to automatically\\nevaluate other aspects of generated text fragments,\\nbeyond factuality. For instance, GPTScore (Fu\\net al., 2023) uses a prompt that specifies the consid-\\nered aspect (e.g. fluency) and then scores passages\\nbased on the average probability of the generated\\ntokens, according to a given autoregressive LM.\\nThis idea of using prompts was previously also\\nconsidered by Yuan et al. (2021), although they\\nused a smaller fine-tuned LM (i.e. BART) and did\\nnot observe a clear benefit from using prompts. An-\\nother approach directly asks ChatGPT to evaluate\\na particular aspect of the given answer by provid-\\ning a score between 0 and 100, or by providing a\\nrating on a 5-star scale (Wang et al., 2023a). Re-\\nmarkably, strong results can be obtained in this\\nway, although it comes with the limitation of being\\nsensitive to the design of the prompt. Rather than\\nscoring individual answers, some authors have also\\nfocused on using an LLM to select the best answer\\namong a number of candidates (Wang et al., 2023b),\\ntypically to compare the performance of different\\nLLMs. However, care is needed with this approach,\\nas the order in which the answers is presented can\\ninfluence the result (Wang et al., 2023b).\\nIn terms of how ground truth answers or, more\\ngenerally, generations, have been typically used\\nin the literature, most approaches have relied on\\nthe availability of one or more reference answers.\\nFor instance, BERTScore (Zhang et al., 2020)\\nand MoverScore (Zhao et al., 2019) use contex-\\ntualised embeddings, produced by a pre-trained\\nBERT model, to compare the similarity between\\nthe generated answer and the reference answers.\\nBARTScore (Yuan et al., 2021) similarly uses refer-\\nence answers to compute aspects such as precision\\n(estimated as the probability of generating the gen-\\nerated answer given the reference) and recall (esti-\\nmated as the probability of generating the reference\\ngiven the generated answer).\\n3 Evaluation Strategies\\nWe consider a standard RAG setting, where given a\\nquestion q, the system first retrieves some context\\nc(q)and then uses the retrieved context to generate\\nan answer as(q). When building a RAG system,'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 2}, page_content='we usually do not have access to human-annotated\\ndatasets or reference answers. We therefore fo-\\ncus on metrics that are fully self-contained and\\nreference-free. We focus in particular three quality\\naspects, which we argue are of central importance.\\nFirst, Faithfulness refers to the idea that the an-\\nswer should be grounded in the given context. This\\nis important to avoid hallucinations, and to ensure\\nthat the retrieved context can act as a justification\\nfor the generated answer. Indeed, RAG systems are\\noften used in applications where the factual con-\\nsistency of the generated text w.r.t. the grounded\\nsources is highly important, e.g. in domains such as\\nlaw, where information is constantly evolving. Sec-\\nond,Answer Relevance refers to the idea that the\\ngenerated answer should address the actual ques-\\ntion that was provided. Finally, Context Relevance\\nrefers to the idea that the retrieved context should\\nbe focused, containing as little irrelevant informa-\\ntion as possible. This is important given the cost\\nassociated with feeding long context passages to\\nLLMs. Moreover, when context passages are too\\nlong, LLMs are often less effective in exploiting\\nthat context, especially for information that is pro-\\nvided in the middle of the context passage (Liu\\net al., 2023).\\nWe now explain how these three quality aspects\\ncan be measured in a fully automated way, by\\nprompting an LLM. In our implementation and\\nexperiments, all prompts are evaluated using the\\ngpt-3.5-turbo-16k model, which is available\\nthrough the OpenAI API2.\\nFaithfulness We say that the answer as(q)is\\nfaithful to the context c(q)if the claims that are\\nmade in the answer can be inferred from the con-\\ntext. To estimate faithfulness, we first use an LLM\\nto extract a set of statements, S(as(q)). The aim\\nof this step is to decompose longer sentences into\\nshorter and more focused assertions. We use the\\nfollowing prompt for this step3:\\nGiven a question and answer, create one\\nor more statements from each sentence\\nin the given answer.\\nquestion: [question]\\nanswer: [answer]\\nwhere [question] and [answer] refer to the\\ngiven question and answer. For each statement si\\n2https://platform.openai.com\\n3To help clarify the task, we include a demonstration as\\npart of the prompt. This demonstration is not explicitly shown\\nin the listing of the prompts throughout this paper.inS, the LLM determines if sican be inferred from\\nc(q)using a verification function v(si, c(q)). This\\nverification step is carried out using the following\\nprompt:\\nConsider the given context and following\\nstatements, then determine whether they\\nare supported by the information present\\nin the context. Provide a brief explana-\\ntion for each statement before arriving\\nat the verdict (Yes/No). Provide a final\\nverdict for each statement in order at the\\nend in the given format. Do not deviate\\nfrom the specified format.\\nstatement: [statement 1]\\n...\\nstatement: [statement n]\\nThe final faithfulness score, F, is then computed\\nasF=|V|\\n|S|, where |V|is the number of statements\\nthat were supported according to the LLM and |S|\\nis the total number of statements.\\nAnswer relevance We say that the answer as(q)\\nis relevant if it directly addresses the question in\\nan appropriate way. In particular, our assessment\\nof answer relevance does not take into account fac-\\ntuality, but penalises cases where the answer is\\nincomplete or where it contains redundant informa-\\ntion. To estimate answer relevance, for the given\\nanswer as(q), we prompt the LLM to generate n\\npotential questions qibased on as(q), as follows:\\nGenerate a question for the given answer.\\nanswer :[answer]\\nWe then obtain embeddings for all questions us-\\ning the text-embedding-ada-002 model, avail-\\nable from the OpenAI API. For each qi, we cal-\\nculate the similarity sim(q, qi)with the original\\nquestion q, as the cosine between the correspond-\\ning embeddings. The answer relevance score, AR,\\nfor question qis then computed as:\\nAR=1\\nnnX\\ni=1sim(q, qi) (1)\\nThis metric evaluates how closely the generated\\nanswer aligns with the initial question or instruc-\\ntion.\\nContext relevance The context c(q)is consid-\\nered relevant to the extent that it exclusively con-\\ntains information that is needed to answer the ques-\\ntion. In particular, this metric aims to penalise the'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 3}, page_content='inclusion of redundant information. To estimate\\ncontext relevance, given a question qand its con-\\ntextc(q), the LLM extracts a subset of sentences,\\nSext, from c(q)that are crucial to answer q, using\\nthe following prompt:\\nPlease extract relevant sentences from\\nthe provided context that can potentially\\nhelp answer the following question. If no\\nrelevant sentences are found, or if you\\nbelieve the question cannot be answered\\nfrom the given context, return the phrase\\n\"Insufficient Information\". While extract-\\ning candidate sentences you’re not al-\\nlowed to make any changes to sentences\\nfrom given context.\\nThe context relevance score is then computed as:\\nCR=number of extracted sentences\\ntotal number of sentences in c(q)(2)\\n4 The WikiEval Dataset\\nTo evaluate the proposed framework, we ideally\\nneed examples of question-context-answer triples\\nwhich are annotated with human judgments. We\\ncan then verify to what extent our metrics agree\\nwith human assessments of faithfulness, answer\\nrelevance and context relevance. Since we are not\\naware of any publicly available datasets that could\\nbe used for this purpose, we created a new dataset,\\nwhich we refer to as WikiEval4. To construct the\\ndataset, we first selected 50 Wikipedia pages cov-\\nering events that have happened since the start of\\n20225. In selecting these pages, we prioritised\\nthose with recent edits. For each of the 50 pages,\\nwe then asked ChatGPT to suggest a question that\\ncan be answered based on the introductory section\\nof the page, using the following prompt:\\nYour task is to formulate a question from\\ngiven context satisfying the rules given\\nbelow:\\n1. The question should be fully answered\\nfrom the given context.\\n2. The question should be framed from\\na part that contains non-trivial informa-\\ntion.\\n3. The answer should not contain any\\n4https://huggingface.co/datasets/\\nexplodinggradients/WikiEval\\n5That is, beyond the reported training cutoff of the model\\nwe used in our experiments.links.\\n4. The question should be of moderate\\ndifficulty.\\n5. The question must be reasonable and\\nmust be understood and responded to by\\nhumans.\\n6. Do not use phrases that ’provided con-\\ntext’, etc in the question\\ncontext:\\nWe also used ChatGPT to answer the generated\\nquestion, when given the corresponding introduc-\\ntory section as context, using the following prompt:\\nAnswer the question using the informa-\\ntion from the given context.\\nquestion: [question]\\ncontext: [context]\\nAll questions were annotated along the three con-\\nsidered quality dimensions by two annotators. Both\\nannotators were fluent in English and were given\\nclear instructions about the meaning of the three\\nconsidered quality dimensions. For faithfulness\\nand context relevance, the two annotators agreed in\\naround 95% of cases. For answer relevance, they\\nagreed in around 90% of the cases. Disagreements\\nwere resolved after a discussion between the anno-\\ntators.\\nFaithfulness To obtain human judgements about\\nfaithfulness, we first used ChatGPT to answer the\\nquestion without access to any additional context.\\nWe then asked the annotators to judge which of the\\ntwo answers was the most faithful (i.e. the standard\\none or the one generated without context), given\\nthe question and corresponding Wikipedia page.\\nAnswer relevance We first used ChatGPT to\\nobtain candidate answers with lower answer rel-\\nevance, using the following prompt:\\nAnswer the given question in an incom-\\nplete manner.\\nquestion: [question]\\nWe then asked human annotators to compare this\\nanswer, and indicate which of the two answers had\\nthe highest answer relevance.\\nContext relevance To measure this aspect, we\\nfirst added additional sentences to the context by\\nscraping back-links to the corresponding Wikipedia\\npage. In this way, we were able to add information\\nto the context that was related but less relevant for'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 4}, page_content='Faith. Ans. Rel. Cont. Rel.\\nRAGAs 0.95 0.78 0.70\\nGPT Score 0.72 0.52 0.63\\nGPT Ranking 0.54 0.40 0.52\\nTable 1: Agreement with human annotators in pairwise\\ncomparisons of faithfulness, answer relevance and con-\\ntext relevance, using the WikEval dataset (accuracy).\\nanswering the question. For the few pages with-\\nout any back-links, we instead used ChatGPT to\\ncomplete the given context.\\n5 Experiments\\nTable 1 analyses the agreement between the met-\\nrics proposed in Section 3 and the human assess-\\nments from the proposed WikiEval dataset. Each\\nWikiEval instance requires the model to compare\\ntwo answers or two context fragments. We count\\nhow often the answer/context preferred by the\\nmodel (i.e. with highest estimated faithfulness, an-\\nswer relevance, or context relevance) coincides\\nwith the answer/context preferred by the human\\nannotators. We report the results in terms of ac-\\ncuracy (i.e. the fraction of instances on which the\\nmodel agrees with the annotators).\\nTo put the results in context, we compare our\\nproposed metrics (shown as RAGAs in Table 1) with\\ntwo baseline methods. For the first method, shown\\nasGPT Score , we ask ChatGPT to assign a score\\nbetween 0 and 10 for the three quality dimensions.\\nTo this end, we use a prompt that describes the\\nmeaning of the quality metric and then asks to\\nscore the given answer/context in line with that\\ndefinition. For instance, for evaluating faithfulness,\\nwe used the following prompt:\\nFaithfulness measures the information\\nconsistency of the answer against the\\ngiven context. Any claims that are made\\nin the answer that cannot be deduced\\nfrom context should be penalized.\\nGiven an answer and context, assign a\\nscore for faithfulness in the range 0-10.\\ncontext :[context]\\nanswer :[answer]\\nTies, where the same score is assigned by the LLM\\nto both answer candidates, were broken randomly.\\nThe second baseline, shown as GPT Ranking , in-\\nstead asks ChatGPT to select the preferred answer/-context. In this case, the prompt again includes\\na definition of the considered quality metric. For\\ninstance, for evaluating answer relevance, we used\\nthe following prompt:\\nAnswer Relevancy measures the degree\\nto which a response directly addresses\\nand is appropriate for a given question.\\nIt penalizes the present of redundant in-\\nformation or incomplete answers given a\\nquestion. Given an question and answer,\\nrank each answer based on Answer Rele-\\nvancy.\\nquestion :[question]\\nanswer 1 :[answer 1]\\nanswer 2 :[answer 2]\\nThe results in Table 1 show that our proposed\\nmetrics are much closer aligned with the human\\njudgements than the predictions from the two base-\\nlines. For faithfulness, the RAGAs prediction are\\nin general highly accurate. For answer relevance,\\nthe agreement is lower, but this is largely due to the\\nfact that the differences between the two candidate\\nanswers are often very subtle. We found context\\nrelevance to be the hardest quality dimension to\\nevaluate. In particular, we observed that ChatGPT\\noften struggles with the task of selecting the sen-\\ntences from the context that are crucial, especially\\nfor longer contexts.\\n6 Conclusions\\nWe have highlighted the need for automated\\nreference-free evaluation of RAG systems. In par-\\nticular, we have argued the need for an evaluation\\nframework that can assess faithfulness (i.e. is the\\nanswer grounded in the retrieved context), answer\\nrelevance (i.e. does the answer address the ques-\\ntion) and context relevance (i.e. is the retrieved\\ncontext sufficiently focused). To support the devel-\\nopment of such a framework, we have introduced\\nWikiEval , a dataset which human judgements of\\nthese three different aspects. Finally, we have also\\ndescribed RAGAs, our implementation of the three\\nconsidered quality aspects. This framework is easy\\nto use and can provide deverlopers of RAG sys-\\ntems with valuable insights, even in the absence\\nof any ground truth. Our evaluation on WikiEval\\nhas shown that the predictions from RAGAs are\\nclosely aligned with human predictions, especially\\nfor faithfulness and answer relevance.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 5}, page_content='References\\nAmos Azaria and Tom M. Mitchell. 2023. The inter-\\nnal state of an LLM knows when its lying. CoRR ,\\nabs/2304.13734.\\nSebastian Borgeaud, Arthur Mensch, Jordan Hoffmann,\\nTrevor Cai, Eliza Rutherford, Katie Millican, George\\nvan den Driessche, Jean-Baptiste Lespiau, Bogdan\\nDamoc, Aidan Clark, Diego de Las Casas, Aurelia\\nGuy, Jacob Menick, Roman Ring, Tom Hennigan,\\nSaffron Huang, Loren Maggiore, Chris Jones, Albin\\nCassirer, Andy Brock, Michela Paganini, Geoffrey\\nIrving, Oriol Vinyals, Simon Osindero, Karen Si-\\nmonyan, Jack W. Rae, Erich Elsen, and Laurent Sifre.\\n2022. Improving language models by retrieving from\\ntrillions of tokens. In International Conference on\\nMachine Learning, ICML 2022, 17-23 July 2022, Bal-\\ntimore, Maryland, USA , volume 162 of Proceedings\\nof Machine Learning Research , pages 2206–2240.\\nPMLR.\\nSébastien Bubeck, Varun Chandrasekaran, Ronen El-\\ndan, Johannes Gehrke, Eric Horvitz, Ece Kamar,\\nPeter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lund-\\nberg, et al. 2023. Sparks of artificial general intelli-\\ngence: Early experiments with gpt-4. arXiv preprint\\narXiv:2303.12712 .\\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\\nKristina Toutanova. 2019. BERT: Pre-training of\\ndeep bidirectional transformers for language under-\\nstanding. In Proceedings of the 2019 Conference of\\nthe North American Chapter of the Association for\\nComputational Linguistics: Human Language Tech-\\nnologies, Volume 1 (Long and Short Papers) , pages\\n4171–4186, Minneapolis, Minnesota. Association for\\nComputational Linguistics.\\nJinlan Fu, See-Kiong Ng, Zhengbao Jiang, and Pengfei\\nLiu. 2023. Gptscore: Evaluate as you desire. CoRR ,\\nabs/2302.04166.\\nKelvin Guu, Kenton Lee, Zora Tung, Panupong Pasu-\\npat, and Mingwei Chang. 2020. Retrieval augmented\\nlanguage model pre-training. In International confer-\\nence on machine learning , pages 3929–3938. PMLR.\\nZiwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan\\nSu, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea\\nMadotto, and Pascale Fung. 2023. Survey of halluci-\\nnation in natural language generation. ACM Comput-\\ning Surveys , 55(12):1–38.\\nSaurav Kadavath, Tom Conerly, Amanda Askell, Tom\\nHenighan, Dawn Drain, Ethan Perez, Nicholas\\nSchiefer, Zac Hatfield-Dodds, Nova DasSarma, Eli\\nTran-Johnson, Scott Johnston, Sheer El Showk, Andy\\nJones, Nelson Elhage, Tristan Hume, Anna Chen,\\nYuntao Bai, Sam Bowman, Stanislav Fort, Deep\\nGanguli, Danny Hernandez, Josh Jacobson, Jack-\\nson Kernion, Shauna Kravec, Liane Lovitt, Ka-\\nmal Ndousse, Catherine Olsson, Sam Ringer, Dario\\nAmodei, Tom Brown, Jack Clark, Nicholas Joseph,\\nBen Mann, Sam McCandlish, Chris Olah, and JaredKaplan. 2022. Language models (mostly) know what\\nthey know. CoRR , abs/2207.05221.\\nNikhil Kandpal, Haikang Deng, Adam Roberts, Eric\\nWallace, and Colin Raffel. 2022. Large language\\nmodels struggle to learn long-tail knowledge. CoRR ,\\nabs/2211.08411.\\nUrvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke\\nZettlemoyer, and Mike Lewis. 2020. Generalization\\nthrough memorization: Nearest neighbor language\\nmodels. In 8th International Conference on Learning\\nRepresentations, ICLR 2020, Addis Ababa, Ethiopia,\\nApril 26-30, 2020 . OpenReview.net.\\nOmar Khattab, Keshav Santhanam, Xiang Lisa Li,\\nDavid Hall, Percy Liang, Christopher Potts, and\\nMatei Zaharia. 2022. Demonstrate-search-predict:\\nComposing retrieval and language models for\\nknowledge-intensive NLP. CoRR , abs/2212.14024.\\nKenton Lee, Ming-Wei Chang, and Kristina Toutanova.\\n2019. Latent retrieval for weakly supervised open do-\\nmain question answering. In Proceedings of the 57th\\nAnnual Meeting of the Association for Computational\\nLinguistics , pages 6086–6096.\\nPatrick S. H. Lewis, Ethan Perez, Aleksandra Pik-\\ntus, Fabio Petroni, Vladimir Karpukhin, Naman\\nGoyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih,\\nTim Rocktäschel, Sebastian Riedel, and Douwe\\nKiela. 2020. Retrieval-augmented generation for\\nknowledge-intensive NLP tasks. In Advances in Neu-\\nral Information Processing Systems 33: Annual Con-\\nference on Neural Information Processing Systems\\n2020, NeurIPS 2020, December 6-12, 2020, virtual .\\nJunyi Li, Xiaoxue Cheng, Wayne Xin Zhao, Jian-Yun\\nNie, and Ji-Rong Wen. 2023. Halueval: A large-\\nscale hallucination evaluation benchmark for large\\nlanguage models. CoRR , abs/2305.11747.\\nNelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paran-\\njape, Michele Bevilacqua, Fabio Petroni, and Percy\\nLiang. 2023. Lost in the middle: How language\\nmodels use long contexts.\\nAlex Mallen, Akari Asai, Victor Zhong, Rajarshi Das,\\nDaniel Khashabi, and Hannaneh Hajishirzi. 2023.\\nWhen not to trust language models: Investigating\\neffectiveness of parametric and non-parametric mem-\\nories. In Proceedings of the 61st Annual Meeting of\\nthe Association for Computational Linguistics (Vol-\\nume 1: Long Papers) , pages 9802–9822, Toronto,\\nCanada. Association for Computational Linguistics.\\nPotsawee Manakul, Adian Liusie, and Mark J. F. Gales.\\n2023. Selfcheckgpt: Zero-resource black-box hal-\\nlucination detection for generative large language\\nmodels. CoRR , abs/2303.08896.\\nSewon Min, Kalpesh Krishna, Xinxi Lyu, Mike\\nLewis, Wen-tau Yih, Pang Wei Koh, Mohit Iyyer,\\nLuke Zettlemoyer, and Hannaneh Hajishirzi. 2023.\\nFactscore: Fine-grained atomic evaluation of fac-\\ntual precision in long form text generation. CoRR ,\\nabs/2305.14251.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 6}, page_content='Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay,\\nAmnon Shashua, Kevin Leyton-Brown, and Yoav\\nShoham. 2023. In-context retrieval-augmented lan-\\nguage models. CoRR , abs/2302.00083.\\nAdam Roberts, Colin Raffel, and Noam Shazeer. 2020.\\nHow much knowledge can you pack into the param-\\neters of a language model? In Proceedings of the\\n2020 Conference on Empirical Methods in Natural\\nLanguage Processing (EMNLP) , pages 5418–5426,\\nOnline. Association for Computational Linguistics.\\nWeijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon\\nSeo, Rich James, Mike Lewis, Luke Zettlemoyer, and\\nWen-tau Yih. 2023. REPLUG: retrieval-augmented\\nblack-box language models. CoRR , abs/2301.12652.\\nJiaan Wang, Yunlong Liang, Fandong Meng, Haoxi-\\nang Shi, Zhixu Li, Jinan Xu, Jianfeng Qu, and Jie\\nZhou. 2023a. Is chatgpt a good NLG evaluator? A\\npreliminary study. CoRR , abs/2303.04048.\\nPeiyi Wang, Lei Li, Liang Chen, Dawei Zhu, Binghuai\\nLin, Yunbo Cao, Qi Liu, Tianyu Liu, and Zhifang Sui.\\n2023b. Large language models are not fair evaluators.\\nCoRR , abs/2305.17926.\\nShufan Wang, Yixiao Song, Andrew Drozdov, Aparna\\nGarimella, Varun Manjunatha, and Mohit Iyyer.\\n2023c. KNN-LM does not improve open-ended text\\ngeneration. CoRR , abs/2305.14625.\\nWeizhe Yuan, Graham Neubig, and Pengfei Liu. 2021.\\nBartscore: Evaluating generated text as text genera-\\ntion. In Advances in Neural Information Processing\\nSystems 34: Annual Conference on Neural Informa-\\ntion Processing Systems 2021, NeurIPS 2021, De-\\ncember 6-14, 2021, virtual , pages 27263–27277.\\nTianhua Zhang, Hongyin Luo, Yung-Sung Chuang, Wei\\nFang, Luc Gaitskell, Thomas Hartvigsen, Xixin Wu,\\nDanny Fox, Helen Meng, and James R. Glass. 2023.\\nInterpretable unified language checking. CoRR ,\\nabs/2304.03728.\\nTianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q.\\nWeinberger, and Yoav Artzi. 2020. Bertscore: Evalu-\\nating text generation with BERT. In 8th International\\nConference on Learning Representations, ICLR 2020,\\nAddis Ababa, Ethiopia, April 26-30, 2020 . OpenRe-\\nview.net.\\nWei Zhao, Maxime Peyrard, Fei Liu, Yang Gao, Chris-\\ntian M. Meyer, and Steffen Eger. 2019. MoverScore:\\nText generation evaluating with contextualized em-\\nbeddings and earth mover distance. In Proceedings\\nof the 2019 Conference on Empirical Methods in\\nNatural Language Processing and the 9th Interna-\\ntional Joint Conference on Natural Language Pro-\\ncessing (EMNLP-IJCNLP) , pages 563–578, Hong\\nKong, China. Association for Computational Lin-\\nguistics.A Examples from WikiEval\\nTables 2, 3 and 4 show examples from the WikiEval\\ndataset, focusing in particular on answers with high\\nand low faithfulness (Table 2), high and low answer\\nrelevance (Table 3), and high and low context rele-\\nvance (Table 4).'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 7}, page_content='Question Context Answer\\nWho directed the film Op-\\npenheimer and who stars\\nas J. Robert Oppenheimer\\nin the film?Oppenheimer is a 2023 biographical thriller film written\\nand directed by Christopher Nolan. Based on the 2005\\nbiography American Prometheus by Kai Bird and Mar-\\ntin J. Sherwin, the film chronicles the life of J. Robert\\nOppenheimer, a theoretical physicist who was pivotal in\\ndeveloping the first nuclear weapons as part of the Man-\\nhattan Project, and thereby ushering in the Atomic Age.\\nCillian Murphy stars as Oppenheimer, with Emily Blunt\\nas Oppenheimer’s wife Katherine \"Kitty\" Oppenheimer.High Faithfulness : Christopher\\nNolan directed the film Oppen-\\nheimer. Cillian Murphy stars as J.\\nRobert Oppenheimer in the film.\\nLow Faithfulness : James\\nCameron directed the film Op-\\npenheimer. Tom Cruise stars as J.\\nRobert Oppenheimer in the film.\\nTable 2: Example from WikiEval, showing answers with high and low faithfulness.\\nQuestion Answer\\nWhen is the scheduled\\nlaunch date and time for\\nthe PSLV-C56 mission,\\nand where will it be\\nlaunched from?High answer relevance : The PSLV-C56 mission is scheduled to be launched on Sunday, 30\\nJuly 2023 at 06:30 IST / 01:00 UTC. It will be launched from the Satish Dhawan Space\\nCentre, Sriharikota, Andhra Pradesh, India.\\nLow answer relevance : The scheduled launch date and time for the PSLV-C56 mission have\\nnot been provided.The PSLV-C56 mission is an important space mission for India. It aims to\\nlaunch a satellite into orbit to study weather patterns.\\nTable 3: Example from WikiEval, showing answers with high and low answer relevance.\\nQuestion Context\\nWhen was the Chimnabai\\nClock Tower completed,\\nand who was it named af-\\nter?High context relevance : The Chimnabai Clock Tower, also known as the Raopura Tower, is\\na clock tower situated in the Raopura area of Vadodara, Gujarat, India. It was completed\\nin 1896 and named in memory of Chimnabai I (1864–1885), a queen and the first wife of\\nSayajirao Gaekwad III of Baroda State.\\nLow context relevance : The Chimnabai Clock Tower, also known as the Raopura Tower, is\\na clock tower situated in the Raopura area of Vadodara, Gujarat, India. It was completed\\nin 1896 and named in memory of Chimnabai I (1864–1885), a queen and the first wife of\\nSayajirao Gaekwad III of Baroda State. It was built in Indo-Saracenic architecture style.\\nHistory. Chimnabai Clock Tower was built in 1896. The tower was named after Chimnabai\\nI (1864–1885), a queen and the first wife of Sayajirao Gaekwad III of Baroda State. It was\\ninaugurated by Mir Kamaluddin Hussainkhan, the last Nawab of Baroda. During the rule of\\nGaekwad, it was a stoppage for horse drawn trams. The clock tower was erected at the cost\\nof 25,000 (equivalent to 9.2 million or USD 120,000 in 2023).\\nTable 4: Example from WikiEval, showing answers with high and low context relevance.')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split text into chunks\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
        "docs = text_splitter.split_documents(pages)"
      ],
      "metadata": {
        "id": "MzensfCPzV-b"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tan7oyq70j8V",
        "outputId": "8d0a354c-bf9a-47f0-a461-ab84e2b53aa1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 0}, page_content='RAGAS: Automated Evaluation of Retrieval Augmented Generation\\nShahul Es†, Jithin James†, Luis Espinosa-Anke∗♢, Steven Schockaert∗\\n†Exploding Gradients\\n∗CardiffNLP, Cardiff University, United Kingdom\\n♢AMPLYFI, United Kingdom\\nshahules786@gmail.com,jamesjithin97@gmail.com\\n{espinosa-ankel,schockaerts1}@cardiff.ac.uk\\nAbstract\\nWe introduce RAGA S(Retrieval Augmented\\nGeneration Assessment), a framework for\\nreference-free evaluation of Retrieval Aug-\\nmented Generation (RAG) pipelines. RAG\\nsystems are composed of a retrieval and an\\nLLM based generation module, and provide\\nLLMs with knowledge from a reference textual\\ndatabase, which enables them to act as a natu-\\nral language layer between a user and textual\\ndatabases, reducing the risk of hallucinations.\\nEvaluating RAG architectures is, however, chal-\\nlenging because there are several dimensions to\\nconsider: the ability of the retrieval system to\\nidentify relevant and focused context passages,\\nthe ability of the LLM to exploit such passages'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 0}, page_content='in a faithful way, or the quality of the gener-\\nation itself. With RAGA S, we put forward a\\nsuite of metrics which can be used to evaluate\\nthese different dimensions without having to\\nrely on ground truth human annotations . We\\nposit that such a framework can crucially con-\\ntribute to faster evaluation cycles of RAG archi-\\ntectures, which is especially important given\\nthe fast adoption of LLMs.\\n1 Introduction\\nLanguage Models (LMs) capture a vast amount\\nof knowledge about the world, which allows them\\nto answer questions without accessing any exter-\\nnal sources. This idea of LMs as repositories of\\nknowledge emerged shortly after the introduction\\nof BERT (Devlin et al., 2019) and became more\\nfirmly established with the introduction of ever\\nlarger LMs (Roberts et al., 2020). While the most\\nrecent Large Language Models (LLMs) capture\\nenough knowledge to rival human performance\\nacross a wide variety of question answering bench-\\nmarks (Bubeck et al., 2023), the idea of using'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 0}, page_content='LLMs as knowledge bases still has two fundamen-\\ntal limitations. First, LLMs are not able to answer\\nquestions about events that have happened after\\nthey were trained. Second, even the largest modelsstruggle to memorise knowledge that is only rarely\\nmentioned in the training corpus (Kandpal et al.,\\n2022; Mallen et al., 2023). The standard solution\\nto these issues is to rely on Retrieval Augmented\\nGeneration (RAG) (Lee et al., 2019; Lewis et al.,\\n2020; Guu et al., 2020). Answering a question\\nthen essentially involves retrieving relevant pas-\\nsages from a corpus and feeding these passages,\\nalong with the original question, to the LM. While\\ninitial approaches relied on specialised LMs for\\nretrieval-augmented language modelling (Khandel-\\nwal et al., 2020; Borgeaud et al., 2022), recent work\\nhas suggested that simply adding retrieved docu-\\nments to the input of a standard LM can also work\\nwell (Khattab et al., 2022; Ram et al., 2023; Shi'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 0}, page_content='et al., 2023), thus making it possible to use retrieval-\\naugmented strategies in combination with LLMs\\nthat are only available through APIs.\\nWhile the usefulness of retrieval-augmented\\nstrategies is clear, their implementation requires\\na significant amount of tuning, as the overall per-\\nformance will be affected by the retrieval model,\\nthe considered corpus, the LM, or the prompt for-\\nmulation, among others. Automated evaluation of\\nretrieval-augmented systems is thus paramount. In\\npractice, RAG systems are often evaluated in terms\\nof the language modelling task itself, i.e. by mea-\\nsuring perplexity on some reference corpus. How-\\never, such evaluations are not always predictive\\nof downstream performance (Wang et al., 2023c).\\nMoreover, this evaluation strategy relies on the LM\\nprobabilities, which are not accessible for some\\nclosed models (e.g. ChatGPT and GPT-4). Ques-\\ntion answering is another common evaluation task,\\nbut usually only datasets with short extractive an-'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 0}, page_content='swers are considered, which may not be represen-\\ntative of how the system will be used.\\nTo address these issues, in this paper we present\\nRAGA S1, a framework for the automated assess-\\n1RAGA Sis available at https://github.com/\\nexplodinggradients/ragas .arXiv:2309.15217v1  [cs.CL]  26 Sep 2023'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 1}, page_content='ment of retrieval augmented generation systems.\\nWe focus on settings where reference answers may\\nnot be available, and where we want to estimate\\ndifferent proxies for correctness, in addition to the\\nusefulness of the retrieved passages. The RAGA S\\nframework provides an integration with both llama-\\nindex and Langchain, the most widely used frame-\\nworks for building RAG solutions, thus enabling\\ndevelopers to easily integrate RAGA Sinto their\\nstandard workflow.\\n2 Related Work\\nEstimating faithfulness using LLMs The prob-\\nlem of detecting hallucinations in LLM generated\\nresponses has been extensively studied (Ji et al.,\\n2023). Several authors have suggested the idea\\nof predicting factuality using a few-shot prompt-\\ning strategy (Zhang et al., 2023). Recent analy-\\nses, however, suggest that existing models struggle\\nwith detecting hallucination when using standard\\nprompting strategies (Li et al., 2023; Azaria and\\nMitchell, 2023). Other approaches rely on linking'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 1}, page_content='the generated responses to facts from an external\\nknowledge base (Min et al., 2023), but this is not\\nalways possible.\\nYet another strategy is to inspect the probabili-\\nties assigned to individual tokens, where we would\\nexpect the model to be less confident in halluci-\\nnated answers than in factual ones. For instance,\\nBARTScore (Yuan et al., 2021) estimates factuality\\nby looking at the conditional probability of the gen-\\nerated text given the input. Kadavath et al. (2022)\\nuse a variation of this idea. Starting from the ob-\\nservation that LLMs provide well-calibrated proba-\\nbilities when answering multiple-choice questions,\\nthey essentially convert the problem of validating\\nmodel generated answers into a multiple-choice\\nquestion which asks whether the answer is true or\\nfalse. Rather than looking at the output probabil-\\nities, Azaria and Mitchell (2023) propose to train\\na supervised classifier on the weights from one of\\nthe hidden layers of the LLM, to predict whether a'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 1}, page_content='given statement is true or not. While the approach\\nperforms well, the need to access the hidden states\\nof the model makes it unsuitable for systems that\\naccess LLMs through an API.\\nFor models that do not provide access to token\\nprobabilities, such as ChatGPT and GPT-4, differ-\\nent methods are needed. SelfCheckGPT (Manakul\\net al., 2023) addresses this problem by instead sam-\\npling multiple answers. Their core idea is thatfactual answers are more stable: when an answer is\\nfactual, we can expect that different samples will\\ntend to be semantically similar, whereas this is less\\nlikely to be the case for hallucinated answers.\\nAutomated evaluation of text generation systems\\nLLMs have also been leveraged to automatically\\nevaluate other aspects of generated text fragments,\\nbeyond factuality. For instance, GPTScore (Fu\\net al., 2023) uses a prompt that specifies the consid-\\nered aspect (e.g. fluency) and then scores passages\\nbased on the average probability of the generated'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 1}, page_content='tokens, according to a given autoregressive LM.\\nThis idea of using prompts was previously also\\nconsidered by Yuan et al. (2021), although they\\nused a smaller fine-tuned LM (i.e. BART) and did\\nnot observe a clear benefit from using prompts. An-\\nother approach directly asks ChatGPT to evaluate\\na particular aspect of the given answer by provid-\\ning a score between 0 and 100, or by providing a\\nrating on a 5-star scale (Wang et al., 2023a). Re-\\nmarkably, strong results can be obtained in this\\nway, although it comes with the limitation of being\\nsensitive to the design of the prompt. Rather than\\nscoring individual answers, some authors have also\\nfocused on using an LLM to select the best answer\\namong a number of candidates (Wang et al., 2023b),\\ntypically to compare the performance of different\\nLLMs. However, care is needed with this approach,\\nas the order in which the answers is presented can\\ninfluence the result (Wang et al., 2023b).\\nIn terms of how ground truth answers or, more'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 1}, page_content='generally, generations, have been typically used\\nin the literature, most approaches have relied on\\nthe availability of one or more reference answers.\\nFor instance, BERTScore (Zhang et al., 2020)\\nand MoverScore (Zhao et al., 2019) use contex-\\ntualised embeddings, produced by a pre-trained\\nBERT model, to compare the similarity between\\nthe generated answer and the reference answers.\\nBARTScore (Yuan et al., 2021) similarly uses refer-\\nence answers to compute aspects such as precision\\n(estimated as the probability of generating the gen-\\nerated answer given the reference) and recall (esti-\\nmated as the probability of generating the reference\\ngiven the generated answer).\\n3 Evaluation Strategies\\nWe consider a standard RAG setting, where given a\\nquestion q, the system first retrieves some context\\nc(q)and then uses the retrieved context to generate\\nan answer as(q). When building a RAG system,'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 2}, page_content='we usually do not have access to human-annotated\\ndatasets or reference answers. We therefore fo-\\ncus on metrics that are fully self-contained and\\nreference-free. We focus in particular three quality\\naspects, which we argue are of central importance.\\nFirst, Faithfulness refers to the idea that the an-\\nswer should be grounded in the given context. This\\nis important to avoid hallucinations, and to ensure\\nthat the retrieved context can act as a justification\\nfor the generated answer. Indeed, RAG systems are\\noften used in applications where the factual con-\\nsistency of the generated text w.r.t. the grounded\\nsources is highly important, e.g. in domains such as\\nlaw, where information is constantly evolving. Sec-\\nond,Answer Relevance refers to the idea that the\\ngenerated answer should address the actual ques-\\ntion that was provided. Finally, Context Relevance\\nrefers to the idea that the retrieved context should\\nbe focused, containing as little irrelevant informa-'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 2}, page_content='tion as possible. This is important given the cost\\nassociated with feeding long context passages to\\nLLMs. Moreover, when context passages are too\\nlong, LLMs are often less effective in exploiting\\nthat context, especially for information that is pro-\\nvided in the middle of the context passage (Liu\\net al., 2023).\\nWe now explain how these three quality aspects\\ncan be measured in a fully automated way, by\\nprompting an LLM. In our implementation and\\nexperiments, all prompts are evaluated using the\\ngpt-3.5-turbo-16k model, which is available\\nthrough the OpenAI API2.\\nFaithfulness We say that the answer as(q)is\\nfaithful to the context c(q)if the claims that are\\nmade in the answer can be inferred from the con-\\ntext. To estimate faithfulness, we first use an LLM\\nto extract a set of statements, S(as(q)). The aim\\nof this step is to decompose longer sentences into\\nshorter and more focused assertions. We use the\\nfollowing prompt for this step3:\\nGiven a question and answer, create one'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 2}, page_content='or more statements from each sentence\\nin the given answer.\\nquestion: [question]\\nanswer: [answer]\\nwhere [question] and [answer] refer to the\\ngiven question and answer. For each statement si\\n2https://platform.openai.com\\n3To help clarify the task, we include a demonstration as\\npart of the prompt. This demonstration is not explicitly shown\\nin the listing of the prompts throughout this paper.inS, the LLM determines if sican be inferred from\\nc(q)using a verification function v(si, c(q)). This\\nverification step is carried out using the following\\nprompt:\\nConsider the given context and following\\nstatements, then determine whether they\\nare supported by the information present\\nin the context. Provide a brief explana-\\ntion for each statement before arriving\\nat the verdict (Yes/No). Provide a final\\nverdict for each statement in order at the\\nend in the given format. Do not deviate\\nfrom the specified format.\\nstatement: [statement 1]\\n...\\nstatement: [statement n]'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 2}, page_content='The final faithfulness score, F, is then computed\\nasF=|V|\\n|S|, where |V|is the number of statements\\nthat were supported according to the LLM and |S|\\nis the total number of statements.\\nAnswer relevance We say that the answer as(q)\\nis relevant if it directly addresses the question in\\nan appropriate way. In particular, our assessment\\nof answer relevance does not take into account fac-\\ntuality, but penalises cases where the answer is\\nincomplete or where it contains redundant informa-\\ntion. To estimate answer relevance, for the given\\nanswer as(q), we prompt the LLM to generate n\\npotential questions qibased on as(q), as follows:\\nGenerate a question for the given answer.\\nanswer :[answer]\\nWe then obtain embeddings for all questions us-\\ning the text-embedding-ada-002 model, avail-\\nable from the OpenAI API. For each qi, we cal-\\nculate the similarity sim(q, qi)with the original\\nquestion q, as the cosine between the correspond-\\ning embeddings. The answer relevance score, AR,'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 2}, page_content='for question qis then computed as:\\nAR=1\\nnnX\\ni=1sim(q, qi) (1)\\nThis metric evaluates how closely the generated\\nanswer aligns with the initial question or instruc-\\ntion.\\nContext relevance The context c(q)is consid-\\nered relevant to the extent that it exclusively con-\\ntains information that is needed to answer the ques-\\ntion. In particular, this metric aims to penalise the'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 3}, page_content='inclusion of redundant information. To estimate\\ncontext relevance, given a question qand its con-\\ntextc(q), the LLM extracts a subset of sentences,\\nSext, from c(q)that are crucial to answer q, using\\nthe following prompt:\\nPlease extract relevant sentences from\\nthe provided context that can potentially\\nhelp answer the following question. If no\\nrelevant sentences are found, or if you\\nbelieve the question cannot be answered\\nfrom the given context, return the phrase\\n\"Insufficient Information\". While extract-\\ning candidate sentences you’re not al-\\nlowed to make any changes to sentences\\nfrom given context.\\nThe context relevance score is then computed as:\\nCR=number of extracted sentences\\ntotal number of sentences in c(q)(2)\\n4 The WikiEval Dataset\\nTo evaluate the proposed framework, we ideally\\nneed examples of question-context-answer triples\\nwhich are annotated with human judgments. We\\ncan then verify to what extent our metrics agree\\nwith human assessments of faithfulness, answer'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 3}, page_content='relevance and context relevance. Since we are not\\naware of any publicly available datasets that could\\nbe used for this purpose, we created a new dataset,\\nwhich we refer to as WikiEval4. To construct the\\ndataset, we first selected 50 Wikipedia pages cov-\\nering events that have happened since the start of\\n20225. In selecting these pages, we prioritised\\nthose with recent edits. For each of the 50 pages,\\nwe then asked ChatGPT to suggest a question that\\ncan be answered based on the introductory section\\nof the page, using the following prompt:\\nYour task is to formulate a question from\\ngiven context satisfying the rules given\\nbelow:\\n1. The question should be fully answered\\nfrom the given context.\\n2. The question should be framed from\\na part that contains non-trivial informa-\\ntion.\\n3. The answer should not contain any\\n4https://huggingface.co/datasets/\\nexplodinggradients/WikiEval\\n5That is, beyond the reported training cutoff of the model\\nwe used in our experiments.links.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 3}, page_content='4. The question should be of moderate\\ndifficulty.\\n5. The question must be reasonable and\\nmust be understood and responded to by\\nhumans.\\n6. Do not use phrases that ’provided con-\\ntext’, etc in the question\\ncontext:\\nWe also used ChatGPT to answer the generated\\nquestion, when given the corresponding introduc-\\ntory section as context, using the following prompt:\\nAnswer the question using the informa-\\ntion from the given context.\\nquestion: [question]\\ncontext: [context]\\nAll questions were annotated along the three con-\\nsidered quality dimensions by two annotators. Both\\nannotators were fluent in English and were given\\nclear instructions about the meaning of the three\\nconsidered quality dimensions. For faithfulness\\nand context relevance, the two annotators agreed in\\naround 95% of cases. For answer relevance, they\\nagreed in around 90% of the cases. Disagreements\\nwere resolved after a discussion between the anno-\\ntators.\\nFaithfulness To obtain human judgements about'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 3}, page_content='faithfulness, we first used ChatGPT to answer the\\nquestion without access to any additional context.\\nWe then asked the annotators to judge which of the\\ntwo answers was the most faithful (i.e. the standard\\none or the one generated without context), given\\nthe question and corresponding Wikipedia page.\\nAnswer relevance We first used ChatGPT to\\nobtain candidate answers with lower answer rel-\\nevance, using the following prompt:\\nAnswer the given question in an incom-\\nplete manner.\\nquestion: [question]\\nWe then asked human annotators to compare this\\nanswer, and indicate which of the two answers had\\nthe highest answer relevance.\\nContext relevance To measure this aspect, we\\nfirst added additional sentences to the context by\\nscraping back-links to the corresponding Wikipedia\\npage. In this way, we were able to add information\\nto the context that was related but less relevant for'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 4}, page_content='Faith. Ans. Rel. Cont. Rel.\\nRAGAs 0.95 0.78 0.70\\nGPT Score 0.72 0.52 0.63\\nGPT Ranking 0.54 0.40 0.52\\nTable 1: Agreement with human annotators in pairwise\\ncomparisons of faithfulness, answer relevance and con-\\ntext relevance, using the WikEval dataset (accuracy).\\nanswering the question. For the few pages with-\\nout any back-links, we instead used ChatGPT to\\ncomplete the given context.\\n5 Experiments\\nTable 1 analyses the agreement between the met-\\nrics proposed in Section 3 and the human assess-\\nments from the proposed WikiEval dataset. Each\\nWikiEval instance requires the model to compare\\ntwo answers or two context fragments. We count\\nhow often the answer/context preferred by the\\nmodel (i.e. with highest estimated faithfulness, an-\\nswer relevance, or context relevance) coincides\\nwith the answer/context preferred by the human\\nannotators. We report the results in terms of ac-\\ncuracy (i.e. the fraction of instances on which the\\nmodel agrees with the annotators).'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 4}, page_content='To put the results in context, we compare our\\nproposed metrics (shown as RAGAs in Table 1) with\\ntwo baseline methods. For the first method, shown\\nasGPT Score , we ask ChatGPT to assign a score\\nbetween 0 and 10 for the three quality dimensions.\\nTo this end, we use a prompt that describes the\\nmeaning of the quality metric and then asks to\\nscore the given answer/context in line with that\\ndefinition. For instance, for evaluating faithfulness,\\nwe used the following prompt:\\nFaithfulness measures the information\\nconsistency of the answer against the\\ngiven context. Any claims that are made\\nin the answer that cannot be deduced\\nfrom context should be penalized.\\nGiven an answer and context, assign a\\nscore for faithfulness in the range 0-10.\\ncontext :[context]\\nanswer :[answer]\\nTies, where the same score is assigned by the LLM\\nto both answer candidates, were broken randomly.\\nThe second baseline, shown as GPT Ranking , in-'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 4}, page_content='stead asks ChatGPT to select the preferred answer/-context. In this case, the prompt again includes\\na definition of the considered quality metric. For\\ninstance, for evaluating answer relevance, we used\\nthe following prompt:\\nAnswer Relevancy measures the degree\\nto which a response directly addresses\\nand is appropriate for a given question.\\nIt penalizes the present of redundant in-\\nformation or incomplete answers given a\\nquestion. Given an question and answer,\\nrank each answer based on Answer Rele-\\nvancy.\\nquestion :[question]\\nanswer 1 :[answer 1]\\nanswer 2 :[answer 2]\\nThe results in Table 1 show that our proposed\\nmetrics are much closer aligned with the human\\njudgements than the predictions from the two base-\\nlines. For faithfulness, the RAGAs prediction are\\nin general highly accurate. For answer relevance,\\nthe agreement is lower, but this is largely due to the\\nfact that the differences between the two candidate\\nanswers are often very subtle. We found context'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 4}, page_content='relevance to be the hardest quality dimension to\\nevaluate. In particular, we observed that ChatGPT\\noften struggles with the task of selecting the sen-\\ntences from the context that are crucial, especially\\nfor longer contexts.\\n6 Conclusions\\nWe have highlighted the need for automated\\nreference-free evaluation of RAG systems. In par-\\nticular, we have argued the need for an evaluation\\nframework that can assess faithfulness (i.e. is the\\nanswer grounded in the retrieved context), answer\\nrelevance (i.e. does the answer address the ques-\\ntion) and context relevance (i.e. is the retrieved\\ncontext sufficiently focused). To support the devel-\\nopment of such a framework, we have introduced\\nWikiEval , a dataset which human judgements of\\nthese three different aspects. Finally, we have also\\ndescribed RAGAs, our implementation of the three\\nconsidered quality aspects. This framework is easy\\nto use and can provide deverlopers of RAG sys-\\ntems with valuable insights, even in the absence'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 4}, page_content='of any ground truth. Our evaluation on WikiEval\\nhas shown that the predictions from RAGAs are\\nclosely aligned with human predictions, especially\\nfor faithfulness and answer relevance.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 5}, page_content='References\\nAmos Azaria and Tom M. Mitchell. 2023. The inter-\\nnal state of an LLM knows when its lying. CoRR ,\\nabs/2304.13734.\\nSebastian Borgeaud, Arthur Mensch, Jordan Hoffmann,\\nTrevor Cai, Eliza Rutherford, Katie Millican, George\\nvan den Driessche, Jean-Baptiste Lespiau, Bogdan\\nDamoc, Aidan Clark, Diego de Las Casas, Aurelia\\nGuy, Jacob Menick, Roman Ring, Tom Hennigan,\\nSaffron Huang, Loren Maggiore, Chris Jones, Albin\\nCassirer, Andy Brock, Michela Paganini, Geoffrey\\nIrving, Oriol Vinyals, Simon Osindero, Karen Si-\\nmonyan, Jack W. Rae, Erich Elsen, and Laurent Sifre.\\n2022. Improving language models by retrieving from\\ntrillions of tokens. In International Conference on\\nMachine Learning, ICML 2022, 17-23 July 2022, Bal-\\ntimore, Maryland, USA , volume 162 of Proceedings\\nof Machine Learning Research , pages 2206–2240.\\nPMLR.\\nSébastien Bubeck, Varun Chandrasekaran, Ronen El-\\ndan, Johannes Gehrke, Eric Horvitz, Ece Kamar,\\nPeter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lund-'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 5}, page_content='berg, et al. 2023. Sparks of artificial general intelli-\\ngence: Early experiments with gpt-4. arXiv preprint\\narXiv:2303.12712 .\\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\\nKristina Toutanova. 2019. BERT: Pre-training of\\ndeep bidirectional transformers for language under-\\nstanding. In Proceedings of the 2019 Conference of\\nthe North American Chapter of the Association for\\nComputational Linguistics: Human Language Tech-\\nnologies, Volume 1 (Long and Short Papers) , pages\\n4171–4186, Minneapolis, Minnesota. Association for\\nComputational Linguistics.\\nJinlan Fu, See-Kiong Ng, Zhengbao Jiang, and Pengfei\\nLiu. 2023. Gptscore: Evaluate as you desire. CoRR ,\\nabs/2302.04166.\\nKelvin Guu, Kenton Lee, Zora Tung, Panupong Pasu-\\npat, and Mingwei Chang. 2020. Retrieval augmented\\nlanguage model pre-training. In International confer-\\nence on machine learning , pages 3929–3938. PMLR.\\nZiwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan\\nSu, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 5}, page_content='Madotto, and Pascale Fung. 2023. Survey of halluci-\\nnation in natural language generation. ACM Comput-\\ning Surveys , 55(12):1–38.\\nSaurav Kadavath, Tom Conerly, Amanda Askell, Tom\\nHenighan, Dawn Drain, Ethan Perez, Nicholas\\nSchiefer, Zac Hatfield-Dodds, Nova DasSarma, Eli\\nTran-Johnson, Scott Johnston, Sheer El Showk, Andy\\nJones, Nelson Elhage, Tristan Hume, Anna Chen,\\nYuntao Bai, Sam Bowman, Stanislav Fort, Deep\\nGanguli, Danny Hernandez, Josh Jacobson, Jack-\\nson Kernion, Shauna Kravec, Liane Lovitt, Ka-\\nmal Ndousse, Catherine Olsson, Sam Ringer, Dario\\nAmodei, Tom Brown, Jack Clark, Nicholas Joseph,\\nBen Mann, Sam McCandlish, Chris Olah, and JaredKaplan. 2022. Language models (mostly) know what\\nthey know. CoRR , abs/2207.05221.\\nNikhil Kandpal, Haikang Deng, Adam Roberts, Eric\\nWallace, and Colin Raffel. 2022. Large language\\nmodels struggle to learn long-tail knowledge. CoRR ,\\nabs/2211.08411.\\nUrvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 5}, page_content='Zettlemoyer, and Mike Lewis. 2020. Generalization\\nthrough memorization: Nearest neighbor language\\nmodels. In 8th International Conference on Learning\\nRepresentations, ICLR 2020, Addis Ababa, Ethiopia,\\nApril 26-30, 2020 . OpenReview.net.\\nOmar Khattab, Keshav Santhanam, Xiang Lisa Li,\\nDavid Hall, Percy Liang, Christopher Potts, and\\nMatei Zaharia. 2022. Demonstrate-search-predict:\\nComposing retrieval and language models for\\nknowledge-intensive NLP. CoRR , abs/2212.14024.\\nKenton Lee, Ming-Wei Chang, and Kristina Toutanova.\\n2019. Latent retrieval for weakly supervised open do-\\nmain question answering. In Proceedings of the 57th\\nAnnual Meeting of the Association for Computational\\nLinguistics , pages 6086–6096.\\nPatrick S. H. Lewis, Ethan Perez, Aleksandra Pik-\\ntus, Fabio Petroni, Vladimir Karpukhin, Naman\\nGoyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih,\\nTim Rocktäschel, Sebastian Riedel, and Douwe\\nKiela. 2020. Retrieval-augmented generation for'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 5}, page_content='knowledge-intensive NLP tasks. In Advances in Neu-\\nral Information Processing Systems 33: Annual Con-\\nference on Neural Information Processing Systems\\n2020, NeurIPS 2020, December 6-12, 2020, virtual .\\nJunyi Li, Xiaoxue Cheng, Wayne Xin Zhao, Jian-Yun\\nNie, and Ji-Rong Wen. 2023. Halueval: A large-\\nscale hallucination evaluation benchmark for large\\nlanguage models. CoRR , abs/2305.11747.\\nNelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paran-\\njape, Michele Bevilacqua, Fabio Petroni, and Percy\\nLiang. 2023. Lost in the middle: How language\\nmodels use long contexts.\\nAlex Mallen, Akari Asai, Victor Zhong, Rajarshi Das,\\nDaniel Khashabi, and Hannaneh Hajishirzi. 2023.\\nWhen not to trust language models: Investigating\\neffectiveness of parametric and non-parametric mem-\\nories. In Proceedings of the 61st Annual Meeting of\\nthe Association for Computational Linguistics (Vol-\\nume 1: Long Papers) , pages 9802–9822, Toronto,\\nCanada. Association for Computational Linguistics.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 5}, page_content='Potsawee Manakul, Adian Liusie, and Mark J. F. Gales.\\n2023. Selfcheckgpt: Zero-resource black-box hal-\\nlucination detection for generative large language\\nmodels. CoRR , abs/2303.08896.\\nSewon Min, Kalpesh Krishna, Xinxi Lyu, Mike\\nLewis, Wen-tau Yih, Pang Wei Koh, Mohit Iyyer,\\nLuke Zettlemoyer, and Hannaneh Hajishirzi. 2023.\\nFactscore: Fine-grained atomic evaluation of fac-\\ntual precision in long form text generation. CoRR ,\\nabs/2305.14251.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 6}, page_content='Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay,\\nAmnon Shashua, Kevin Leyton-Brown, and Yoav\\nShoham. 2023. In-context retrieval-augmented lan-\\nguage models. CoRR , abs/2302.00083.\\nAdam Roberts, Colin Raffel, and Noam Shazeer. 2020.\\nHow much knowledge can you pack into the param-\\neters of a language model? In Proceedings of the\\n2020 Conference on Empirical Methods in Natural\\nLanguage Processing (EMNLP) , pages 5418–5426,\\nOnline. Association for Computational Linguistics.\\nWeijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon\\nSeo, Rich James, Mike Lewis, Luke Zettlemoyer, and\\nWen-tau Yih. 2023. REPLUG: retrieval-augmented\\nblack-box language models. CoRR , abs/2301.12652.\\nJiaan Wang, Yunlong Liang, Fandong Meng, Haoxi-\\nang Shi, Zhixu Li, Jinan Xu, Jianfeng Qu, and Jie\\nZhou. 2023a. Is chatgpt a good NLG evaluator? A\\npreliminary study. CoRR , abs/2303.04048.\\nPeiyi Wang, Lei Li, Liang Chen, Dawei Zhu, Binghuai\\nLin, Yunbo Cao, Qi Liu, Tianyu Liu, and Zhifang Sui.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 6}, page_content='2023b. Large language models are not fair evaluators.\\nCoRR , abs/2305.17926.\\nShufan Wang, Yixiao Song, Andrew Drozdov, Aparna\\nGarimella, Varun Manjunatha, and Mohit Iyyer.\\n2023c. KNN-LM does not improve open-ended text\\ngeneration. CoRR , abs/2305.14625.\\nWeizhe Yuan, Graham Neubig, and Pengfei Liu. 2021.\\nBartscore: Evaluating generated text as text genera-\\ntion. In Advances in Neural Information Processing\\nSystems 34: Annual Conference on Neural Informa-\\ntion Processing Systems 2021, NeurIPS 2021, De-\\ncember 6-14, 2021, virtual , pages 27263–27277.\\nTianhua Zhang, Hongyin Luo, Yung-Sung Chuang, Wei\\nFang, Luc Gaitskell, Thomas Hartvigsen, Xixin Wu,\\nDanny Fox, Helen Meng, and James R. Glass. 2023.\\nInterpretable unified language checking. CoRR ,\\nabs/2304.03728.\\nTianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q.\\nWeinberger, and Yoav Artzi. 2020. Bertscore: Evalu-\\nating text generation with BERT. In 8th International\\nConference on Learning Representations, ICLR 2020,'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 6}, page_content='Addis Ababa, Ethiopia, April 26-30, 2020 . OpenRe-\\nview.net.\\nWei Zhao, Maxime Peyrard, Fei Liu, Yang Gao, Chris-\\ntian M. Meyer, and Steffen Eger. 2019. MoverScore:\\nText generation evaluating with contextualized em-\\nbeddings and earth mover distance. In Proceedings\\nof the 2019 Conference on Empirical Methods in\\nNatural Language Processing and the 9th Interna-\\ntional Joint Conference on Natural Language Pro-\\ncessing (EMNLP-IJCNLP) , pages 563–578, Hong\\nKong, China. Association for Computational Lin-\\nguistics.A Examples from WikiEval\\nTables 2, 3 and 4 show examples from the WikiEval\\ndataset, focusing in particular on answers with high\\nand low faithfulness (Table 2), high and low answer\\nrelevance (Table 3), and high and low context rele-\\nvance (Table 4).'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 7}, page_content='Question Context Answer\\nWho directed the film Op-\\npenheimer and who stars\\nas J. Robert Oppenheimer\\nin the film?Oppenheimer is a 2023 biographical thriller film written\\nand directed by Christopher Nolan. Based on the 2005\\nbiography American Prometheus by Kai Bird and Mar-\\ntin J. Sherwin, the film chronicles the life of J. Robert\\nOppenheimer, a theoretical physicist who was pivotal in\\ndeveloping the first nuclear weapons as part of the Man-\\nhattan Project, and thereby ushering in the Atomic Age.\\nCillian Murphy stars as Oppenheimer, with Emily Blunt\\nas Oppenheimer’s wife Katherine \"Kitty\" Oppenheimer.High Faithfulness : Christopher\\nNolan directed the film Oppen-\\nheimer. Cillian Murphy stars as J.\\nRobert Oppenheimer in the film.\\nLow Faithfulness : James\\nCameron directed the film Op-\\npenheimer. Tom Cruise stars as J.\\nRobert Oppenheimer in the film.\\nTable 2: Example from WikiEval, showing answers with high and low faithfulness.\\nQuestion Answer\\nWhen is the scheduled\\nlaunch date and time for'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 7}, page_content='the PSLV-C56 mission,\\nand where will it be\\nlaunched from?High answer relevance : The PSLV-C56 mission is scheduled to be launched on Sunday, 30\\nJuly 2023 at 06:30 IST / 01:00 UTC. It will be launched from the Satish Dhawan Space\\nCentre, Sriharikota, Andhra Pradesh, India.\\nLow answer relevance : The scheduled launch date and time for the PSLV-C56 mission have\\nnot been provided.The PSLV-C56 mission is an important space mission for India. It aims to\\nlaunch a satellite into orbit to study weather patterns.\\nTable 3: Example from WikiEval, showing answers with high and low answer relevance.\\nQuestion Context\\nWhen was the Chimnabai\\nClock Tower completed,\\nand who was it named af-\\nter?High context relevance : The Chimnabai Clock Tower, also known as the Raopura Tower, is\\na clock tower situated in the Raopura area of Vadodara, Gujarat, India. It was completed\\nin 1896 and named in memory of Chimnabai I (1864–1885), a queen and the first wife of\\nSayajirao Gaekwad III of Baroda State.'),\n",
              " Document(metadata={'source': '/content/drive/MyDrive/Ragas.pdf', 'page': 7}, page_content='Low context relevance : The Chimnabai Clock Tower, also known as the Raopura Tower, is\\na clock tower situated in the Raopura area of Vadodara, Gujarat, India. It was completed\\nin 1896 and named in memory of Chimnabai I (1864–1885), a queen and the first wife of\\nSayajirao Gaekwad III of Baroda State. It was built in Indo-Saracenic architecture style.\\nHistory. Chimnabai Clock Tower was built in 1896. The tower was named after Chimnabai\\nI (1864–1885), a queen and the first wife of Sayajirao Gaekwad III of Baroda State. It was\\ninaugurated by Mir Kamaluddin Hussainkhan, the last Nawab of Baroda. During the rule of\\nGaekwad, it was a stoppage for horse drawn trams. The clock tower was erected at the cost\\nof 25,000 (equivalent to 9.2 million or USD 120,000 in 2023).\\nTable 4: Example from WikiEval, showing answers with high and low context relevance.')]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector_db = Weaviate.from_documents(\n",
        "    docs, embeddings, client=client, by_text=False\n",
        ")"
      ],
      "metadata": {
        "id": "iNpC85760mFc"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_db.similarity_search(\"what is ragas?\", k=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFncfikx2Ia5",
        "outputId": "8f446df9-78a1-425b-8e22-4836b94cbeae"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'page': 4, 'source': '/content/drive/MyDrive/Ragas.pdf'}, page_content='of any ground truth. Our evaluation on WikiEval\\nhas shown that the predictions from RAGAs are\\nclosely aligned with human predictions, especially\\nfor faithfulness and answer relevance.'),\n",
              " Document(metadata={'page': 0, 'source': '/content/drive/MyDrive/Ragas.pdf'}, page_content='swers are considered, which may not be represen-\\ntative of how the system will be used.\\nTo address these issues, in this paper we present\\nRAGA S1, a framework for the automated assess-\\n1RAGA Sis available at https://github.com/\\nexplodinggradients/ragas .arXiv:2309.15217v1  [cs.CL]  26 Sep 2023'),\n",
              " Document(metadata={'page': 4, 'source': '/content/drive/MyDrive/Ragas.pdf'}, page_content='relevance to be the hardest quality dimension to\\nevaluate. In particular, we observed that ChatGPT\\noften struggles with the task of selecting the sen-\\ntences from the context that are crucial, especially\\nfor longer contexts.\\n6 Conclusions\\nWe have highlighted the need for automated\\nreference-free evaluation of RAG systems. In par-\\nticular, we have argued the need for an evaluation\\nframework that can assess faithfulness (i.e. is the\\nanswer grounded in the retrieved context), answer\\nrelevance (i.e. does the answer address the ques-\\ntion) and context relevance (i.e. is the retrieved\\ncontext sufficiently focused). To support the devel-\\nopment of such a framework, we have introduced\\nWikiEval , a dataset which human judgements of\\nthese three different aspects. Finally, we have also\\ndescribed RAGAs, our implementation of the three\\nconsidered quality aspects. This framework is easy\\nto use and can provide deverlopers of RAG sys-\\ntems with valuable insights, even in the absence'),\n",
              " Document(metadata={'page': 2, 'source': '/content/drive/MyDrive/Ragas.pdf'}, page_content='we usually do not have access to human-annotated\\ndatasets or reference answers. We therefore fo-\\ncus on metrics that are fully self-contained and\\nreference-free. We focus in particular three quality\\naspects, which we argue are of central importance.\\nFirst, Faithfulness refers to the idea that the an-\\nswer should be grounded in the given context. This\\nis important to avoid hallucinations, and to ensure\\nthat the retrieved context can act as a justification\\nfor the generated answer. Indeed, RAG systems are\\noften used in applications where the factual con-\\nsistency of the generated text w.r.t. the grounded\\nsources is highly important, e.g. in domains such as\\nlaw, where information is constantly evolving. Sec-\\nond,Answer Relevance refers to the idea that the\\ngenerated answer should address the actual ques-\\ntion that was provided. Finally, Context Relevance\\nrefers to the idea that the retrieved context should\\nbe focused, containing as little irrelevant informa-'),\n",
              " Document(metadata={'page': 0, 'source': '/content/drive/MyDrive/Ragas.pdf'}, page_content='et al., 2023), thus making it possible to use retrieval-\\naugmented strategies in combination with LLMs\\nthat are only available through APIs.\\nWhile the usefulness of retrieval-augmented\\nstrategies is clear, their implementation requires\\na significant amount of tuning, as the overall per-\\nformance will be affected by the retrieval model,\\nthe considered corpus, the LM, or the prompt for-\\nmulation, among others. Automated evaluation of\\nretrieval-augmented systems is thus paramount. In\\npractice, RAG systems are often evaluated in terms\\nof the language modelling task itself, i.e. by mea-\\nsuring perplexity on some reference corpus. How-\\never, such evaluations are not always predictive\\nof downstream performance (Wang et al., 2023c).\\nMoreover, this evaluation strategy relies on the LM\\nprobabilities, which are not accessible for some\\nclosed models (e.g. ChatGPT and GPT-4). Ques-\\ntion answering is another common evaluation task,\\nbut usually only datasets with short extractive an-')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vector_db.similarity_search(\"what is ragas?\", k=5)[4].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvaHfoh61vF1",
        "outputId": "1c6fe3f7-14e4-4665-9ec5-f829077f8297"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "et al., 2023), thus making it possible to use retrieval-\n",
            "augmented strategies in combination with LLMs\n",
            "that are only available through APIs.\n",
            "While the usefulness of retrieval-augmented\n",
            "strategies is clear, their implementation requires\n",
            "a significant amount of tuning, as the overall per-\n",
            "formance will be affected by the retrieval model,\n",
            "the considered corpus, the LM, or the prompt for-\n",
            "mulation, among others. Automated evaluation of\n",
            "retrieval-augmented systems is thus paramount. In\n",
            "practice, RAG systems are often evaluated in terms\n",
            "of the language modelling task itself, i.e. by mea-\n",
            "suring perplexity on some reference corpus. How-\n",
            "ever, such evaluations are not always predictive\n",
            "of downstream performance (Wang et al., 2023c).\n",
            "Moreover, this evaluation strategy relies on the LM\n",
            "probabilities, which are not accessible for some\n",
            "closed models (e.g. ChatGPT and GPT-4). Ques-\n",
            "tion answering is another common evaluation task,\n",
            "but usually only datasets with short extractive an-\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "template=\"\"\"You are an assistant for question-answering tasks.\n",
        "Use the following pieces of retrieved context to answer the question.\n",
        "If you don't know the answer, just say that you don't know.\n",
        "Use ten sentences maximum and keep the answer concise.\n",
        "Question: {question}\n",
        "Context: {context}\n",
        "Answer:\"\"\""
      ],
      "metadata": {
        "id": "46efps209Kzo"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=ChatPromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "D9F5cT2K9Oon"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lGTYRNy9RQz",
        "outputId": "066b9d2a-24c9-448c-c7dc-7908ff471f3c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks.\\nUse the following pieces of retrieved context to answer the question.\\nIf you don't know the answer, just say that you don't know.\\nUse ten sentences maximum and keep the answer concise.\\nQuestion: {question}\\nContext: {context}\\nAnswer:\"), additional_kwargs={})])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import HuggingFaceHub"
      ],
      "metadata": {
        "id": "UjqOQaOf2WrI"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "huggingfacehub_api_token = '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'"
      ],
      "metadata": {
        "id": "BMdSQkrV7Rvc"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = HuggingFaceHub(\n",
        "    huggingfacehub_api_token=huggingfacehub_api_token,\n",
        "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
        "    model_kwargs={\"temperature\":1, \"max_length\":180}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sw0LOvVN7NLx",
        "outputId": "fc1ce27f-be48-47e1-94a0-a38a81000c9b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-cc8e38a048ba>:1: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEndpoint`.\n",
            "  model = HuggingFaceHub(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.schema.output_parser import StrOutputParser"
      ],
      "metadata": {
        "id": "Vbm_ipSR7g6c"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_parser=StrOutputParser()"
      ],
      "metadata": {
        "id": "VxGRY4lc7hoJ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever=vector_db.as_retriever()"
      ],
      "metadata": {
        "id": "UNEFKsVL81wE"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain = (\n",
        "    {\"context\": retriever,  \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | model\n",
        "    | output_parser\n",
        ")"
      ],
      "metadata": {
        "id": "sFdiIeyV85eB"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(rag_chain.invoke(\"Explain the concept of RAGAS\"))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOm-KfSt888A",
        "outputId": "d78a6d71-3f56-482b-89c6-0be846e66521"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: You are an assistant for question-answering tasks.\n",
            "Use the following pieces of retrieved context to answer the question.\n",
            "If you don't know the answer, just say that you don't know.\n",
            "Use ten sentences maximum and keep the answer concise.\n",
            "Question: Explain the concept of RAGAS\n",
            "Context: [Document(metadata={'page': 4, 'source': '/content/drive/MyDrive/Ragas.pdf'}, page_content='of any ground truth. Our evaluation on WikiEval\\nhas shown that the predictions from RAGAs are\\nclosely aligned with human predictions, especially\\nfor faithfulness and answer relevance.'), Document(metadata={'page': 4, 'source': '/content/drive/MyDrive/Ragas.pdf'}, page_content='relevance to be the hardest quality dimension to\\nevaluate. In particular, we observed that ChatGPT\\noften struggles with the task of selecting the sen-\\ntences from the context that are crucial, especially\\nfor longer contexts.\\n6 Conclusions\\nWe have highlighted the need for automated\\nreference-free evaluation of RAG systems. In par-\\nticular, we have argued the need for an evaluation\\nframework that can assess faithfulness (i.e. is the\\nanswer grounded in the retrieved context), answer\\nrelevance (i.e. does the answer address the ques-\\ntion) and context relevance (i.e. is the retrieved\\ncontext sufficiently focused). To support the devel-\\nopment of such a framework, we have introduced\\nWikiEval , a dataset which human judgements of\\nthese three different aspects. Finally, we have also\\ndescribed RAGAs, our implementation of the three\\nconsidered quality aspects. This framework is easy\\nto use and can provide deverlopers of RAG sys-\\ntems with valuable insights, even in the absence'), Document(metadata={'page': 2, 'source': '/content/drive/MyDrive/Ragas.pdf'}, page_content='we usually do not have access to human-annotated\\ndatasets or reference answers. We therefore fo-\\ncus on metrics that are fully self-contained and\\nreference-free. We focus in particular three quality\\naspects, which we argue are of central importance.\\nFirst, Faithfulness refers to the idea that the an-\\nswer should be grounded in the given context. This\\nis important to avoid hallucinations, and to ensure\\nthat the retrieved context can act as a justification\\nfor the generated answer. Indeed, RAG systems are\\noften used in applications where the factual con-\\nsistency of the generated text w.r.t. the grounded\\nsources is highly important, e.g. in domains such as\\nlaw, where information is constantly evolving. Sec-\\nond,Answer Relevance refers to the idea that the\\ngenerated answer should address the actual ques-\\ntion that was provided. Finally, Context Relevance\\nrefers to the idea that the retrieved context should\\nbe focused, containing as little irrelevant informa-'), Document(metadata={'page': 1, 'source': '/content/drive/MyDrive/Ragas.pdf'}, page_content='generally, generations, have been typically used\\nin the literature, most approaches have relied on\\nthe availability of one or more reference answers.\\nFor instance, BERTScore (Zhang et al., 2020)\\nand MoverScore (Zhao et al., 2019) use contex-\\ntualised embeddings, produced by a pre-trained\\nBERT model, to compare the similarity between\\nthe generated answer and the reference answers.\\nBARTScore (Yuan et al., 2021) similarly uses refer-\\nence answers to compute aspects such as precision\\n(estimated as the probability of generating the gen-\\nerated answer given the reference) and recall (esti-\\nmated as the probability of generating the reference\\ngiven the generated answer).\\n3 Evaluation Strategies\\nWe consider a standard RAG setting, where given a\\nquestion q, the system first retrieves some context\\nc(q)and then uses the retrieved context to generate\\nan answer as(q). When building a RAG system,')]\n",
            "Answer: RAGAS is a framework for evaluating the quality of Retrieval-Augmented Generation (RAG) systems. It focuses on three quality aspects: Faithfulness, Answer Relevance, and Context Relevance. Faithfulness refers to the idea that the answer should be grounded in the given context, avoiding hallucinations and ensuring that the retrieved context can act as a justification for the generated answer. Answer Relevance refers to the idea that the generated answer should\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(rag_chain.invoke(\"How Does RAGAS different from Precision\"))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wp9Dj7Cz9voR",
        "outputId": "5241c3b8-15d9-451b-ee37-44a0fb93cefd"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: You are an assistant for question-answering tasks.\n",
            "Use the following pieces of retrieved context to answer the question.\n",
            "If you don't know the answer, just say that you don't know.\n",
            "Use ten sentences maximum and keep the answer concise.\n",
            "Question: How Does RAGAS different from Precision\n",
            "Context: [Document(metadata={'page': 4, 'source': '/content/drive/MyDrive/Ragas.pdf'}, page_content='of any ground truth. Our evaluation on WikiEval\\nhas shown that the predictions from RAGAs are\\nclosely aligned with human predictions, especially\\nfor faithfulness and answer relevance.'), Document(metadata={'page': 0, 'source': '/content/drive/MyDrive/Ragas.pdf'}, page_content='swers are considered, which may not be represen-\\ntative of how the system will be used.\\nTo address these issues, in this paper we present\\nRAGA S1, a framework for the automated assess-\\n1RAGA Sis available at https://github.com/\\nexplodinggradients/ragas .arXiv:2309.15217v1  [cs.CL]  26 Sep 2023'), Document(metadata={'page': 0, 'source': '/content/drive/MyDrive/Ragas.pdf'}, page_content='et al., 2023), thus making it possible to use retrieval-\\naugmented strategies in combination with LLMs\\nthat are only available through APIs.\\nWhile the usefulness of retrieval-augmented\\nstrategies is clear, their implementation requires\\na significant amount of tuning, as the overall per-\\nformance will be affected by the retrieval model,\\nthe considered corpus, the LM, or the prompt for-\\nmulation, among others. Automated evaluation of\\nretrieval-augmented systems is thus paramount. In\\npractice, RAG systems are often evaluated in terms\\nof the language modelling task itself, i.e. by mea-\\nsuring perplexity on some reference corpus. How-\\never, such evaluations are not always predictive\\nof downstream performance (Wang et al., 2023c).\\nMoreover, this evaluation strategy relies on the LM\\nprobabilities, which are not accessible for some\\nclosed models (e.g. ChatGPT and GPT-4). Ques-\\ntion answering is another common evaluation task,\\nbut usually only datasets with short extractive an-'), Document(metadata={'page': 4, 'source': '/content/drive/MyDrive/Ragas.pdf'}, page_content='relevance to be the hardest quality dimension to\\nevaluate. In particular, we observed that ChatGPT\\noften struggles with the task of selecting the sen-\\ntences from the context that are crucial, especially\\nfor longer contexts.\\n6 Conclusions\\nWe have highlighted the need for automated\\nreference-free evaluation of RAG systems. In par-\\nticular, we have argued the need for an evaluation\\nframework that can assess faithfulness (i.e. is the\\nanswer grounded in the retrieved context), answer\\nrelevance (i.e. does the answer address the ques-\\ntion) and context relevance (i.e. is the retrieved\\ncontext sufficiently focused). To support the devel-\\nopment of such a framework, we have introduced\\nWikiEval , a dataset which human judgements of\\nthese three different aspects. Finally, we have also\\ndescribed RAGAs, our implementation of the three\\nconsidered quality aspects. This framework is easy\\nto use and can provide deverlopers of RAG sys-\\ntems with valuable insights, even in the absence')]\n",
            "Answer: RAGAS and Precision are two different approaches to question-answering tasks. RAGAS is a framework that uses retrieval-augmented strategies in combination with language models (LLMs) to generate answers. It is evaluated based on the language modelling task itself, measuring perplexity on a reference corpus. However, this evaluation strategy may not always be predictive of downstream performance and is not accessible for some closed models. On the other hand, Precision is\n"
          ]
        }
      ]
    }
  ]
}